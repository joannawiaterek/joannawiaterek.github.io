<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://joannawiaterek.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://joannawiaterek.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-22T02:48:21+00:00</updated><id>https://joannawiaterek.github.io/feed.xml</id><title type="html">Joanna Wiaterek</title><subtitle>Hi, this is Asia. I am a social anthropologist interested in global development, global governance of AI and benefit-sharing. I have lots of questions about effective aid, innovation and inequality, and the impact of AI on the global order. I did my undergrad at Cambridge in Human, Social and Political Sciences. Recently, I have finished my Masters at LSE where I wrote my dissertation on the inclusivity of the UN AI governance. Currently, I am co-founding the [Equiano Institute](https://www.equiano.institute/) where we research societal impacts of AI with a particulat focus on developing countries. In a different life I would probably be a theatre actress. I love sports, cooking and learning foreign languages. Get in touch!&gt;</subtitle><entry><title type="html">The Shoes of the Fisherman (1968) and Morality in AI Leadership</title><link href="https://joannawiaterek.github.io/blog/2025/Shoes-of-the-Fisherman-AI/" rel="alternate" type="text/html" title="The Shoes of the Fisherman (1968) and Morality in AI Leadership"/><published>2025-06-23T06:40:16+00:00</published><updated>2025-06-23T06:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2025/Shoes-of-the-Fisherman-AI</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2025/Shoes-of-the-Fisherman-AI/"><![CDATA[<p><em>“(…) We are acutely conscious of Our duty to pay particular attention to the serious problem of world peace. (…) Our aim must be to educate mankind to sentiments and policies which are opposed to violent and deadly conflicts and to foster just, rational, and peaceful relations between States.”</em> <a href="https://www.vatican.va/content/paul-vi/en/encyclicals/documents/hf_p-vi_enc_06081964_ecclesiam.html">Pope Paul VI, 1964</a></p> <p>I have recently watched the 1968 film ‘<a href="https://en.wikipedia.org/wiki/The_Shoes_of_the_Fisherman_(film)">The Shoes of the Fisherman</a>’, based on Morris West’s 1963 novel. It is a story of a Ukrainian Archbishop, Kiril Lakota, released from a Siberian labour camp after 20 years, sent to Rome, elevated to a Cardinal, and - unexpectedly - elected Pope. All that amid the context of the Cold War politics, widespread famine in China, and the looming threat of nuclear conflict. To me, Lakota embodies what I admire most in personal life and what I lack most in the AI industry: wisdom, discernment and humility.</p> <p>I couldn’t help but draw parallels to today’s threats to humanity posed by AI, the geopolitical tensions, and the rise of a new (American) Pope Leo XIV. There are three key things I wanted to double down on:</p> <h4 id="wisdom--moral-leadership-in-a-polarised-world">Wisdom | Moral Leadership in a Polarised World</h4> <p>Lakota refused to be weaponised by any of the political blocs. Instead, he pursued dialogue and his quiet authority of conscience.</p> <p>Today, polarisation permeates multiple axes of the AI age. Geopolitically, the narrative of US-China AI competition <a href="https://www.techpolicy.press/the-politics-of-ai-benefit-sharing/">paralyses</a> multilateral cooperation. Philosophically, AI safety advocates have become ostracised by the proponents of unrestrained innovation, leading to potentially disastrous policies, such as the <a href="https://www.poynter.org/fact-checking/2025/ai-regulation-ban-one-big-beautiful-bill-trump-congress/">proposed</a> decade-long US ban on AI regulation. Economically, the already vast global inequality levels are at risk of radically <a href="https://www.imf.org/en/Publications/WP/Issues/2025/04/11/The-Global-Impact-of-AI-Mind-the-Gap-566129">magnifying</a>.</p> <p>But real leadership chooses long-term wisdom over short-term wins. And my hope is that as an AI governance community, we find the courage to navigate this polarisation, not with ambition or fear, but with moral grounding.</p> <h4 id="discernment--battle-to-win-vs-people-to-serve">Discernment | Battle to Win vs People to Serve</h4> <p>Spoiler alert: The film ends with Lakota pledging Church’s wealth to save the lives of the Chinese brothers and sisters in famine. That is a result of his deep private deliberation on how to lead the world into collaboration and peace.</p> <p>His actions starkly contrast with hoarding AI resources (e.g. compute), power concentration, and unequal access to AI benefits. Like Lakota, we also need to reframe our challenges: from dominance to responsibility, from fear to care. I see AI governance as a vocation of care because these technologies, if stewarded wisely, could help people around the world live safer, fuller, and more meaningful lives. The responsibility of those steering AI development is to ensure exactly that. And so I ask myself, what the world would look like if the goal of AI development were not to “win”, but to serve.</p> <h4 id="humility--ai-risks-are-real">Humility | AI Risks are Real</h4> <p>Every day, I walk through the city and wonder what our daily lives will feel like in 2, 5 or 10 years amid the vast AI <a href="https://www.nber.org/reporter/2024number4/economics-transformative-ai">transformations</a>. What <a href="https://futurism.com/anthropic-ai-destroy-jobs">jobs</a> will we have, if any? How will we <a href="https://intelligence-curse.ai/">value</a> ourselves, our role and contribution to society? Will we have the peace of mind to cherish our families?</p> <p>Lakota showed that leadership isn’t about certainty, but about conscience. He didn’t know immediately what to do about mitigating the global nuclear conflict, but he knew his core responsibilities and guiding principles. Today, policy-makers must accept the burden of leadership and navigate the potential AI threats amid differing priorities and complex technical <a href="https://www.gov.uk/government/publications/international-ai-safety-report-2025">capabilities</a>. The stakes are high: misjudging the severity of AI risks may cause all of humanity to suffer. And unfortunately, we are in no way prepared for the scale of disruption that many experts <a href="https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html">warn</a> is coming.</p> <p>Humility doesn’t mean paralysis. It means remembering that we are custodians, not gods. That the point is not just to move fast, but to move wisely. Not to dominate, but to serve.</p> <p>Together, wisdom, discernment and humility may be our strongest weapons against an AI catastrophe. And I hope that Pope Leo XIV, who has stepped into the shoes of the fisherman, helps shape the morality of AI governance.</p> <p>I’m currently also finishing a book, ‘<a href="https://www.regnery.com/9781610171540/the-divine-plan/">The Divine Plan</a>’, that depicts the relationship between President Ronald Reagan and Pope John Paul II, and their purpose-driven leadership to end the Cold War. Highly recommend!</p>]]></content><author><name></name></author><category term="AI"/><category term="Christianity"/><summary type="html"><![CDATA[Some brief weekend thoughts…]]></summary></entry><entry><title type="html">Could the Vatican mediate US-China AI peace?</title><link href="https://joannawiaterek.github.io/blog/2025/Vatican-US-China-AI-peace/" rel="alternate" type="text/html" title="Could the Vatican mediate US-China AI peace?"/><published>2025-06-19T16:40:16+00:00</published><updated>2025-06-19T16:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2025/Vatican-US-China-AI-peace</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2025/Vatican-US-China-AI-peace/"><![CDATA[<p>As the US and China accelerate toward frontier AI capabilities, the risk of <a href="https://ai-2027.com/">catastrophic miscalculation</a> grows. The current density of geopolitical tensions made me reflect on the historical contributions of the Holy See to international peace-making. In this post, I explore the role that the Vatican could play in mediating the US-China AI dialogue by drawing on relevant precedents and proposing three action scenarios.</p> <h3 id="what-are-the-stakes-of-the-us-china-agi-race">What are the stakes of the US-China AGI race?</h3> <p>The announcement of China’s DeepSeek R1 model took the West by <a href="https://www.bbc.co.uk/news/articles/c5yv5976z9po">surprise</a> when it matched the performance of the OpenAI model at the time, potentially at a fraction of the costs. As a result, it intensified the rhetoric around the US-China AI arms race. Palantir’s Chief Technology Officer went so far as to <a href="https://www.investors.com/news/technology/palantir-stock-chief-technology-officer-declares-us-china-ai-arms-race/">comment</a>: <em>“I think the real lesson, a more profound one, is that we are at war with China. We are in an AI arms race,”</em>.</p> <p>Amid the “winner takes it all” logic of developing superintelligence, the US and China are depicted as racing to secure strategic supremacy – economically, ideologically, and militarily – through control over transformative AI capabilities. Whatever stage the actual “race” is at, its narrative, especially in the West, has <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5278644">played</a> a significant role in justifying <a href="https://www.forbes.com/sites/lanceeliot/2025/02/18/ai-doomers-versus-ai-accelerationists-locked-in-battle-for-future-of-humanity/">accelerationism</a> and reducing regulatory oversight. Broadly, these intensifying tensions between the frontier AI states matter gravely to humanity, for at least three reasons:</p> <ul> <li><strong>Geopolitical risk</strong>: Multilateralism is further breaking down. The combination of rapidly accelerating capabilities and strategic opacity – each side’s uncertainty about the other’s true progress – raises the likelihood of miscalculations, pre-emptive moves, and dangerous escalation.</li> <li><strong>Distortion of AI development priorities</strong>: Instead of being guided by long-term human needs – such as safety, accessibility, and alignment with social values – AI development is increasingly shaped by zero-sum national competition. This distorts incentives and potentially produces capabilities that transform daily life without our democratic input or ethical oversight.</li> <li><strong>Missed opportunities for global good</strong>: The promises of the use of AI to tackle the near-term shared global challenges, like climate change or poverty, are deeply neglected in the name of achieving a greater level of AI capabilities that could theoretically solve these problems in the future.</li> </ul> <p>However, an arms race benefits no one. US-China AI competition increases the chances of costly, potentially catastrophic conflicts, deepens societal and regulatory unpreparedness for the transformations to come, and incentivises frontier AI developers to compromise on safety rigour. Amid other emerging instabilities, such as the ongoing Russia-Ukraine war or the recent Iran-Israel strikes, the <a href="https://www.wired.com/story/ai-cold-war-china-could-doom-us-all/">AI Cold War</a> further increases the risk of a catastrophic global war – one with consequences humanity may not be able to recover from.</p> <p>On World Peace Day in 2000, John Paul II <a href="https://centeronconscience.org/pope-john-paul-ii/">said</a>, <em>“War is a defeat for humanity.”</em> – it fuels hatred, fragmentation and injustice; and it directly opposes God’s commandment in <a href="https://www.biblegateway.com/passage/?search=John%2013%3A34&amp;version=NIV">John 13:34</a> to love one another, just as God has loved us. That is why, amid the escalating AI tensions between the US and China, there is an urgent need for dialogue. It is not a time to further inflame competition, but rather a time to put humanity’s interests first, demystify uncertainties, and accordingly recalibrate the pace and direction of AI development. A trusted third party – unbound by military or economic ambition, and committed to peace and human flourishing – may be able to create the space for dialogue that global politics alone cannot. Trusting the Vatican’s desire to act in humanity’s best interests, I explore here its potential role in mediating US-China AI peace.</p> <h3 id="why-could-the-vatican-be-the-mediator">Why could the Vatican be the mediator?</h3> <p><em>“War is never inevitable. Weapons can and must fall silent, for they never solve problems but only intensify them. Those who sow peace will endure throughout history, not those who reap victims. Others are not enemies to hate but human beings with whom to speak.”</em> <a href="https://x.com/Pontifex/status/1922656394421104681">Pope Leo XIV, 2025</a></p> <p>The Compendium of the Social Doctrine of the Church <a href="https://www.vatican.va/roman_curia/pontifical_councils/justpeace/documents/rc_pc_justpeace_doc_20060526_compendio-dott-soc_en.html">emphasises</a> that the promotion of peace in the world is an integral part of the Church’s mission of continuing Christ’s work of redemption on earth. This principle, alongside the Vatican’s commitment to global peace and security, <a href="https://www.humandevelopment.va/en.html">“integral human development”</a>, and the common good, have compelled and informed its previous interventions in international peacemaking and conflict resolution. Particularly relevant here is the parallel of Vatican-led international deliberations on nuclear weapons and disarmament. Here are a few key events:</p> <ul> <li>In 1948, amid the realisation of the potential catastrophic power of nuclear weapons, Pope Pius XII held the papal office and <a href="https://ploughshares.org/article/pope-leo-xiv-nuclear-weapons-policy/">stated</a> that they are <em>“the most terrible weapon that the human mind has ever conceived.”</em></li> <li>In 1963, Pope John XXIII wrote an encyclical, <a href="https://www.vatican.va/content/john-xxiii/en/encyclicals/documents/hf_j-xxiii_enc_11041963_pacem.html">Pacem In Terris</a>, which explicitly addressed nuclear weapons: <em>“Nuclear weapons must be banned. A general agreement must be reached on a suitable disarmament program, with an effective system of mutual control.”</em></li> <li>During the 1980s, Pope John Paul II addressed the United Nations on deterrence as a means towards complete disarmament, and the Pontifical Academy of Sciences in Vatican City served as a neutral forum for scientists to discuss nuclear science and policy. Examples of the Academy’s publications emphasising the unprecedented scale of potential nuclear catastrophe include: <ul> <li>1981: <a href="https://www.pas.va/en/publications/documenta/documenta03.html">Statement of the Consequences of the Use of Nuclear Weapons</a></li> <li>1982: <a href="https://www.pas.va/en/publications/documenta/documenta07.html">Report on the International Conference on Nuclear Power Experience</a></li> <li>1982: <a href="https://www.pas.va/en/publications/documenta/documenta04.html">Declaration on Prevention of Nuclear War</a></li> <li>1984: <a href="https://www.pas.va/en/publications/documenta/documenta11.html">Nuclear Winter: A Warning</a></li> </ul> </li> <li>During his visit to Japan in 2019, Pope Francis <a href="https://www.vatican.va/content/francesco/en/speeches/2019/november/documents/papa-francesco_20191124_messaggio-incontropace-hiroshima.html">expressed</a> a condemnation of nuclear weapons: <em>“The use of atomic energy for purposes of war is immoral, just as the possession of nuclear weapons is immoral … How can we speak of peace even as we build terrifying new weapons of war?”</em> Further, Pope Francis continued raising awareness on the destabilising <a href="https://www.vaticannews.va/en/pope/news/2024-07/pope-reconsider-the-development-of-lethal-autonomous-weapons.html">effects</a> of AI on the future of warfare and the world order, potentially exacerbating the nuclear risks.</li> </ul> <p>Together, these actions show that the Vatican can engage deeply and proactively with technologies that could imperil humanity, and to do so from a place of moral neutrality, not geopolitical interest. Today, frontier AI poses similarly destabilising risks. And yet, no international body currently provides direct mediation of the US and China growing tensions in AI development. Here, the Vatican could step in.</p> <p>However, would either side listen? While JD Vance is a Catholic convert and has recently expressed that he’d welcome the Pope’s moral leadership on AI, China and the Vatican have no formal diplomatic ties.</p> <p><em>An exerpt from JD Vance’s recent <a href="https://www.nytimes.com/2025/05/21/opinion/jd-vance-pope-trump-immigration.html">comment</a> during a NYT interview: “(…) part of this arms race component is if we take a pause, does the People’s Republic of China not take a pause? And then we find ourselves all enslaved to P.R.C.-mediated A.I.?</em></p> <p><em>One thing I’ll say, we’re here at the Embassy in Rome, and I think that this is one of the most profound and positive things that Pope Leo could do, not just for the church but for the world. The American government is not equipped to provide moral leadership, at least full-scale moral leadership, in the wake of all the changes that are going to come along with A.I. I think the church is.</em></p> <p><em>This is the sort of thing the church is very good at. This is what the institution was built for in many ways, and I hope that they really do play a very positive role. I suspect that they will.”</em></p> <p>The Vatican cannot dictate AI policy – but it doesn’t need to. Its power and contribution lie in moral convening and impartiality: it does not seek AGI supremacy, nor does it compete for military dominance. Instead, it prioritises the protection of human dignity and global peace. Through an institution like the <a href="https://www.pas.va/en/about.html">Pontifical Academy of Sciences</a> – whose members now include DeepMind CEO Demis Hassabis – the Vatican has the intellectual and ethical capital to initiate dialogue. Since 1603, the Academy has convened experts of high moral profile and significant value of their research to advance the progress of science. Today, it holds the potential to fill in the AI governance gap, bring together the US and China and mitigate global escalations.</p> <h3 id="potential-action-scenarios-for-the-vatican">Potential Action Scenarios for the Vatican</h3> <p>I now sketch out three examples of how the Vatican, specifically via the Pontifical Academy of Sciences and the Papacy, could advance US-China AI peace:</p> <p><strong>Scenario 1</strong>: The Pontifical Academy of Sciences convenes leading US and Chinese scientists for a Study Day or Week focused on frontier AI risks—especially societal and existential ones.</p> <ul> <li><em>Intended output</em>: A report on AI risks to which both the US and Chinese academics contributed and that offers an insight into the respective sides’ threat perceptions and policy priorities.</li> <li><em>Precedent/parallel</em>: In 2010, ahead of the Nuclear Non-Proliferation Treaty Review Conference, PAS <a href="https://www.pas.va/content/dam/casinapioiv/pas/pdf-volumi/scripta-varia/sv115pas.pdf">hosted</a> a similar Study Week on disarmament and peacebuilding. The Vatican emphasised that short-term national security logics must not override long-term peace and global security.</li> <li><em>Strengths</em>: <ul> <li>Involves key scientific voices from the frontier AI states, facilitates knowledge sharing, and encourages a culture of collaboration.</li> <li>Low diplomatic stakes, yet potential for norm shaping among the US and Chinese AI academics and developers.</li> </ul> </li> <li><em>Limitations</em>: <ul> <li>Limited influence on national AI policies, so outcomes may remain primarily symbolic or academic.</li> <li>A one-off event which doesn’t maintain channels for US-China academic exchanges.</li> </ul> </li> </ul> <p><strong>Scenario 2</strong>: The Pontifical Academy of Science hosts a recurring bilateral forum (e.g. every 6 months) where leading AI scientists from the US and China exchange insights and forecasts to de-escalate mutual uncertainty and the potential of conflict.</p> <ul> <li><em>Intended output</em>: A sustained, trust-building channel where top US and Chinese researchers and technical advisors can regularly share AI forecasts, safety concerns, and governance developments.</li> <li><em>Precedent/parallel</em>: In the 1980s, PAS served as a forum for scientists from both sides of the Iron Curtain to exchange ideas on nuclear issues. The <a href="https://idais.ai/dialogues/">International Dialogues on AI Safety</a>, led by the Safe AI Forum, also provide a helpful parallel.</li> <li><em>Strengths</em>: <ul> <li>More intentional about information exchange and consensus-building than the one-off Study Day or Week.</li> <li>The recurring nature of the event maintains relationships and trust over time.</li> <li>Allows for building a shared risk perception around AGI capabilities, safety and societal impacts.</li> </ul> </li> <li><em>Limitations</em>: <ul> <li>Requires sustained commitment and willingness to participate during politically tense moments.</li> <li>The influence may still be limited to academia, with uncertain trickle-down into national security or AI labs circles.</li> </ul> </li> </ul> <p><strong>Scenario 3</strong>: Pope Leo XIV welcomes the US and Chinese officials for AI dialogues to negotiate an agreement.</p> <ul> <li><em>Intended output</em>: A binding international agreement on the de-escalation of the AI arms race.</li> <li><em>Precedent/parallel</em>: Pope John Paul II’s moral interventions during the Cold War (e.g. in <a href="https://www.osvnews.com/st-john-paul-ii-drives-cause-of-freedom-for-humankind-20-years-after-death-say-world-leaders/">Poland</a>, or in nuclear disarmament <a href="https://www.vatican.va/content/john-paul-ii/en/messages/pont_messages/1982/documents/hf_jp-ii_mes_19820607_disarmo-onu.html">advocacy</a>). The Vatican’s involvement in negotiating the <a href="https://www.vaticannews.va/en/pope/news/2024-11/pope-dialogue-prevented-war-between-chile-and-argentina.html">1984</a> Treaty of Peace and Friendship between Chile and Argentina, and the <a href="https://www.theguardian.com/world/2014/dec/17/us-cuba-pope-franicis-key-roles">2014</a> Cuba–US rapprochement.</li> <li><em>Strengths</em>: <ul> <li>High-level of information-sharing between the national officials from both the US and China.</li> <li>The official dialogue would directly inform the US and China’s national AI policies.</li> <li>It could catalyse public awareness and normative pressure, even if the agreement is not reached.</li> </ul> </li> <li><em>Limitations</em>: <ul> <li>The dialogue may be dismissed as idealistic unless preceded by strategic groundwork (e.g. via Scenarios 1 and 2).</li> <li>Key decisions do not rest with governments alone, but with AI labs, which are partly independent of the state.</li> <li>The Vatican has no enforcement power.</li> <li>Uncertainty about the political buy-in from the US and China to participate.</li> </ul> </li> </ul> <p>While the Vatican cannot enforce treaties or dictate national priorities, its ability to convene, moralise, and humanise the debate remains unique. In a field dominated by power, speed, and opacity, the Church’s moral voice could be exactly the guidance we need.</p> <p>I aimed to point out a case for why and how the Vatican could be a meaningful mediator of the US-China AI dialogues. There is an array of specific details that would need to be addressed once the Vatican decides to initiate them. I’m convinced about the feasibility of the three scenarios outlined above, and I am filled with hope by the vision that the Vatican – an advocate of humanity’s flourishing – could lead the pathway toward peace.</p>]]></content><author><name></name></author><category term="AI"/><category term="Christianity"/><summary type="html"><![CDATA[A reflection on the Vatican's peace-making engagements and potential action scenarios towards de-escalating US-China AI tensions.]]></summary></entry><entry><title type="html">The Vatican’s Lessons for AI Benefit-Sharing</title><link href="https://joannawiaterek.github.io/blog/2025/Vatican's-Lessons-AI-BS/" rel="alternate" type="text/html" title="The Vatican’s Lessons for AI Benefit-Sharing"/><published>2025-06-04T10:00:06+00:00</published><updated>2025-06-04T10:00:06+00:00</updated><id>https://joannawiaterek.github.io/blog/2025/Vatican&apos;s-Lessons-AI-BS</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2025/Vatican&apos;s-Lessons-AI-BS/"><![CDATA[<p>Last update: 4/6/2025</p> <h2 id="introduction-ai-vs-humanitywho-serves-whom">Introduction: AI vs Humanity–Who serves whom?</h2> <p>Designing artificial intelligence (AI) so that it serves all of humanity–not just a few amongst us–is the defining challenge of this decade. Today’s innovation optimisation and AI race-dynamics, which result in the centralisation of AI resources and profits, compromises the universal human right to a share in scientific advancement and its benefits (Article 27; United Nations, <a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">1948</a>).</p> <p>Amid these complex power-and-profit dynamics, the absence of a shared moral compass and prioritisation frameworks in international AI governance can lead to choices that further benefit the powerful and neglect urgent global needs. This reflection explores how Vatican-inspired moral principles may guide us through these policy challenges.</p> <p>Reflecting on the relationship between AI and peace, Pope Francis (<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">2024</a>) emphasised that technology shall “serve our best human potential and our highest aspirations.” He revisited that narrative in Antiqua et Nova (<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html">2024</a>), where he wrote that “the order of things must be subordinate to the order of persons, and not the other way around.” I feel deeply empowered by the idea that AI tools could enhance what’s important and meaningful to me.</p> <p>However, I worry we are not exactly on track. The fast pace of improvements in AI capabilities behind closed doors, and the centralised decision-making among a few frontier labs on what AI is and what it should do, create a dynamic where it is AI that shapes our future, rather than the other way round. Paraphrasing Pope Francis’ words, it feels like humanity and the possibilities of our future are subordinate to the order of technological progress, instead of us designing and deploying AI towards the futures which truly fulfil our aspirations.</p> <p>In the face of the AI rush for efficiency, the goal of this post is to prompt a pause – a reflection. It won’t offer implementation guidelines or solutions, but it may lay a seed for future ones. I explore the potential contributions of the Vatican’s teachings in helping us inform prioritisation in AI benefit-sharing.</p> <h2 id="moral-vacancy-in-ai-benefit-sharing-priorities">Moral Vacancy in AI Benefit-Sharing Priorities</h2> <p>The international AI policy space lacks clear prioritisation of human-centred outcomes. While many AI ethics frameworks exist, many remain abstract or politically vulnerable to US-China tensions or frontier labs’ economic incentives. As a result, decisions are guided more by power and profit than by moral principle.</p> <p>International AI benefit-sharing refers to efforts that foster international access to AI’s economic or broader societal benefits (Dennis et al., <a href="https://www.governance.ai/research-paper/options-and-motivations-for-international-ai-benefit-sharing">2024</a>) and holds the potential to mitigate an array of challenges stemming from the current state of AI development. Through regulation and agreements, benefit-sharing could help us re-position AI in service to humanity, especially those historically left behind.</p> <p>International benefit-sharing won’t happen by default and requires a shared understanding of policy priorities. Currently, decisions around AI priorities are often shaped by competitive pressures, not moral commitments:</p> <ul> <li>Frontier labs race toward AGI, incentivised more by investor pressure than by public benefit.</li> <li>The US-China competition limits multilateral transparency and cooperation.</li> <li>Basic deployment opportunities—for example, AI in climate forecasting or low-resource healthcare—are overlooked in favour of speculative future gains.</li> </ul> <p>This leads to a troubling inversion: technology dictates our agenda, instead of serving a shared vision of human flourishing. Without clear priorities, we risk optimising for technological ambition rather than human need.</p> <p>On a personal level, amid claims regarding the whole of humanity – a noble, yet abstract notion behind which we can hide our selfish ambitions – I long to revisit my own heart and reflect on what values I bring into AI policy. It’s easy to speak of benefiting all people while neglecting the needs right in front of us—a friend, a colleague, a family member. If we can’t honour the dignity of individuals in our daily lives, how can we claim to act on behalf of the world?</p> <p>Pope Francis called for “a renewed wisdom of heart” (Antiqua et Nova, <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html">2024</a>). This stands in stark contrast to the technocratic language of AI development evoking efficiency and the deterministic nature of algorithms. As policy-makers, researchers or leaders, we face serious responsibilities regarding shaping AI to the benefit of all–those we know and those whom we’ll never know. Personally, I wish we preserved our values of mutual care and respect and the intrinsic value of human life as we design our futures.</p> <p>While there are existing ethical AI frameworks, such as the Final Report by the United Nation’s High-level Advisory Body on AI (<a href="https://www.un.org/sites/un2.un.org/files/governing_ai_for_humanity_final_report_en.pdf">2024</a>), UNESCO’s recommendations on AI ethics (<a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">2021</a>), or even national AI strategies, among others, they either leave the guidelines in the realm of abstraction or are prone to political climates. This reflection on the Vatican’s contributions is an attempt to explore how its teachings could help us inform prioritisation in AI benefit-sharing. It is an invitation for the Vatican to engage more in setting the priorities for AI policies, and an invitation to all of us working on AI to pause and ask ourselves what we really care about.</p> <h2 id="the-vaticans-lessons-for-ai-benefit-sharing">The Vatican’s Lessons for AI Benefit-Sharing</h2> <p>Why the Vatican? Because its centuries-long expertise lies in humanity and community. Catholic Social Teaching, an area of Catholic doctrine focused on aspects such as human dignity, social justice, and wealth distribution, seems highly relevant for AI benefit-sharing. These teachings, whether you see them as theological or philosophical, can offer insights for navigating the design of AI systems that serve the global common good. There is also something about the Vatican’s view of the intrinsic value in human beings and our lives that is lacking from state- or private-actors’ agendas, whose incentives are subject to the fluctuating geopolitical winds.</p> <p>Moreover, the Vatican has already made significant attempts to engage with AI ethics. Alongside Pope Francis’ writings and the new Pope Leo XIV’s immediate reference, upon his election, to AI as a grand challenge of this century, the Rome Call for AI Ethics (<a href="https://www.romecall.org/wp-content/uploads/2022/03/RomeCall_Paper_web.pdf">2020</a>) brought together signatories from international organizations, governments, institutions and technology companies, and established <em>“a sense of shared responsibility […] in an effort to create a future in which digital innovation and technological progress grant man his centrality.”</em> The participants committed to AI development that <em>“serves every person and humanity as a whole; that respects the dignity of the human person, so that every individual can benefit from the advances of technology; and that does not have as its sole goal greater profit or the gradual replacement of people in the workplace.”</em></p> <p>I selected three headlines to discuss some aspects of the Catholic Social Teaching that could help us ground both intra- and inter-State AI benefit-sharing principles:</p> <h4 id="the-human-person-must-come-before-profit">The Human Person Must Come Before Profit</h4> <p>Catholic thought has long warned against economic systems that reduce people to instruments of production. In Rerum Novarum (<a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html">1891</a>), Pope Leo XIII condemned the exploitation of workers under industrial capitalism, asserting the primacy of the human person over the pursuit of profit. Applied to the context of AI, this principle challenges us to design systems that enhance human dignity. It urges us to ask: Are AI innovations serving the well-being of individuals, or merely driving economic efficiency? For example, technology transfers, as part of non-monetary benefit-sharing, should not be measured by GDP contribution alone, but by how these tools improve daily lives and life satisfaction. More concretely, this also suggests that future AI benefit-sharing agreements should include an obligation for companies profiting from global data flows to compensate the communities whose data they have extracted.</p> <p>In policy terms: profit-sharing mechanisms, ethical deployment standards, and labour protections for those displaced or augmented by AI are moral imperatives—not afterthoughts.</p> <h4 id="preferential-option-for-the-poor">Preferential Option for the Poor</h4> <p>A cornerstone of Catholic ethics, the “preferential option for the poor” asserts that social and political decisions should prioritise those most marginalised. This is not about charity, but long-term, structural justice—shaping systems so that those historically excluded are placed at the centre and gain agency over their destiny.</p> <p>In the AI context, this principle demands more than access: it requires deliberate prioritisation of the Global Majority, low-resource settings, and marginalised groups in AI research, development, and deployment. This might involve funding AI projects in indigenous languages, building local data infrastructures, or offering special concessions for compute access in developing countries.</p> <p>Global AI governance mechanisms can reflect this teaching by embedding equity at their core—as a starting point.</p> <h4 id="truth-in-service-of-the-common-good">Truth in Service of the Common Good</h4> <p>In a world increasingly shaped by algorithmic persuasion and performative policy, Catholic Social Teaching’s emphasis on truth is a necessary corrective. AI systems—especially generative ones—threaten to flood public discourse with falsehoods, deepen epistemic divides, and erode trust.</p> <p>This principle reminds us that benefit-sharing must be grounded not only in economic redistribution but also in the defence of shared truths. We need governance frameworks that uphold transparency, accuracy, and integrity in AI models, such as those used in information systems or education.</p> <p>Beyond fact-checking, this is a call for AI that serves what is deeply real and enduring: human relationships, intergenerational responsibility, and our shared moral aspirations. We must resist the temptation to optimise for short-term engagement or superficial metrics, and instead build AI that contributes to what Pope Francis called “<a href="https://catholicecology.net/blog/pope-francis-what-integral-human-development">integral human development</a>.”</p> <p>While rooted in religious tradition, these principles resonate far beyond church walls—echoing values found in existing treaties. Here are some examples (emphases mine):</p> <ul> <li>Declaration on Social Progress and Development (1969, UN General Assembly) <ul> <li>Article 13(a): <em>Equitable</em> sharing of scientific and technological advances by developed and developing countries, and a steady increase in the use of science and technology for the benefit of the social development of society.</li> </ul> </li> <li>Declaration on the Use of Scientific and Technological Progress (1975, UN General Assembly) <ul> <li>Aware that the <em>transfer of science and technology is one of the principal ways of accelerating the economic development of developing countries</em>,</li> <li>Article 3: All States shall take measures to ensure that scientific and technological achievements <em>satisfy the material and spiritual needs of all sectors of the population</em>.</li> </ul> </li> <li>Rio Declaration on Environment and Development (1992, UN Earth Summit) <ul> <li>Principle 6: The special situation and needs of <em>developing countries</em>, particularly the least developed and those most environmentally vulnerable, <em>shall be given special priority</em>.</li> </ul> </li> </ul> <p>Both the Vatican and existing human rights and development treaties provide solid foundations for setting priorities in benefit-sharing. Our challenge lies in transcending the complex geopolitical and economic tensions unique to AI and applying these guiding principles to this new layer of global governance.</p> <h2 id="moving-forward">Moving Forward</h2> <p>Moral reflections are prone to becoming romanticised debates lacking the world’s realism. It is implementation that is the hard part. But in moments of rapid change, such as AI development, we need ethical North Stars like the Vatican more than ever. Without them, policies risk being reactive and short-sighted.</p> <p>There is a large literature from previous international benefit-sharing agreements and the Holy See’s archives on the fundamental ethical non-negotiables that, as we build the international AI governance ecosystem, we should keep closely in mind despite the fast-paced and almost overpowering speed of technological innovation in comparison to our human pace. It is we who should subordinate and harness AI, not the other way round.</p> <p>As international AI governance takes further shape and the possibility emerges for a global convention on fair and equitable AI benefit-sharing, it is the existing moral teachings, such as those of the Vatican, that will help us construct this new layer of international law. Unfortunately, we may not have much time to do the thinking when the moment comes, so I encourage you to consider deeply today: What future do you want for our world?</p> <h2 id="further-readings">Further Readings</h2> <p><a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html">Rerum Novarum (May 15, 1891)</a> <a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20090629_caritas-in-veritate.html">Caritas in veritate (June 29, 2009)</a> <a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">LVII World Day of Peace 2024 - Artificial Intelligence and Peace</a> <a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit nos (24 October 2024)</a> <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html">Antiqua et nova. Note on the Relationship Between Artificial Intelligence and Human Intelligence (28 January 2025)</a> <a href="https://www.vatican.va/roman_curia/pontifical_councils/justpeace/documents/rc_pc_justpeace_doc_20060526_compendio-dott-soc_en.html#INTRODUCTION">Compendium of the Social Doctrine of the Church</a></p>]]></content><author><name></name></author><category term="AI,"/><category term="Christianity"/><summary type="html"><![CDATA[A reflection on the potential contributions of the Vatican’s teachings in helping us inform prioritisation in AI benefit-sharing.]]></summary></entry><entry><title type="html">Global Governance of AI: preliminary questions</title><link href="https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI/" rel="alternate" type="text/html" title="Global Governance of AI: preliminary questions"/><published>2024-03-28T16:40:16+00:00</published><updated>2024-03-28T16:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI/"><![CDATA[<p>Last update: 17/1/2024</p> <h4 id="context">Context</h4> <p>Most discussions surrounding AI are relatively recent and still highly neglected. Yet, when it comes to the questions related to AI and the Global South, especially, AI-related implications on the global economic and political order, the space seems even more overlooked.</p> <p>There are four key aspects to distinguish:</p> <ol> <li>Design of AI systems (e.g. Who is included in designing and regulating the AI models (compute, data, expertise)?)</li> <li>Bridging the AI divide (e.g. How to advance technological capabilities and independence among the Global South actors?)</li> <li>Global Governance of AI (e.g. What should inclusive institutions look like to ensure benefit-sharing?)</li> <li>Post-A(G)I World Order (e.g. Who has access to the emerging AI models and abilities to harness them? What will the impacts be of e.g. AI automation, AI-generated wealth, on the existing global economic and political order?)</li> </ol> <p>There is an urgent need for a more widespread debate on the global implications of AI, its feasible and equitable governance structures, and ensuring a fair global AI regulation system before it is too late.</p> <h4 id="problem">Problem</h4> <p>The existing work on the impacts of AI automation or regulation is highly localised, predominantly referring to the so-called “Global North” countries (e.g. <a href="https://philiptrammell.com/static/economic_growth_under_transformative_ai.pdf">Trammel and Korinek 2023</a>). In fact, most of the “discussion about the consequences and regulation of AI is occurring among countries whose populations make up just 1.3 billion people” (<a href="https://foreignpolicy.com/2023/05/29/ai-regulation-global-south-artificial-intelligence/">Muggah and Carvalho 2023</a>). What about the Global Majority?</p> <p>The implications of any major innovation are inescapably global and so the innovations in question require a global, collaborative approach.</p> <p>It is critical to expand the AI debate beyond the national concerns of the Global North and to address the world-scale questions concerning issues including the risks from AI in widening global income inequality, the potential challenges of AI to the current political structures, or perpetuation of existing global injustices and structural imbalances through the AI systems (<a href="https://www.soas.ac.uk/study/blog/how-can-ai-better-serve-people-global-south">Batabyal 2023</a>). The world as a whole needs a more cooperative design of AI governance (e.g., <a href="https://www.governance.ai/post/the-case-for-including-the-global-south-in-ai-governance-conversations">Adan 2023</a>, <a href="https://blogs.lse.ac.uk/medialse/2023/06/13/what-can-african-countries-do-to-regulate-artificial-intelligence/">Obia 2023</a>), and ensuring favourable effects from AI on global welfare, especially for the world’s poorest.</p> <hr/> <h4 id="questions">Questions</h4> <h5 id="global-southaiequity">Global South/AI/Equity</h5> <ol> <li>What aspects of AI could specific Global South actors become leaders in? What makes them suitable leaders? How to seize that leadership? Long-term effects of that leadership?</li> <li>What are the unobvious, yet potentially highly effective South-South and North-South coalition in AI governance?</li> <li>How to ensure that Africa has at least a fair start to the AI-related opportunities for economic growth, increase in average welfare, and AI regulations? a) What could multi-stakeholder and benefit-sharing regulations look like? b) When will the window of opportunity close? c) Questions of data abuse? d) How to avoid AI being merely another instrument of the Global North domination, but include the Global South in the “AI lifecycle” (<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/puar.13648">Moon 2023</a>)?</li> <li>How to achieve AI equity if the world is still suffering from unequal access to previous innovations, such as electricity or the Internet? a) How will different countries benefit unequally from AI? What implications will this inequality have? b) How to avoid further concentration of wealth and knowledge? What implications could such concentrated accumulation of technologies have on world poverty and inequality? c) Are there any possibilities for less-developed countries to benefit from not being limited by existing infrastructure / regulations / etc.? (e.g. bypassing centralised fossil fuel-powered electric grids entirely by some countries and going straight to distributed renewable-based electric grids)</li> </ol> <h5 id="ai--eradication-of-global-poverty">AI &amp; Eradication of Global Poverty</h5> <ol> <li>What are the “best buys” in AI4D? a) What evidence is lacking?</li> <li>How to bridge the global AI divide? a) What role can foreign aid play here? b) How to foster technological independence?</li> <li>What global inequalities can AI generate/exacerbate? a) What structural inequalities will be exacerbated? What about the coupling of past, current and future inequalities?</li> <li>How to leverage the AI potential to eradicate extreme poverty and raise the bottom tail of the global income distribution to a fruitful living standard, simultaneously controlling the potential expansive inequality growth? a) What system/regulation would have to be in place to create a kind of global, social protection in order to ensure the poorest are not left behind?</li> <li>Is there an emerging role for the private sector to eradicate extreme poverty and raise the GDP of the Global South?</li> <li>Are the global poor going to have a good, flourishing life in a post-AI world? a) Will the global poor play any role in the critical inputs to AI systems (compute, data, talent, experts implementing algorithms)?</li> <li>What could a global social protection system look like to mitigate the AI-crises [e.g. wealth inequality, existential threats]?</li> <li>How out of touch from one another are the states (increasingly) becoming? The skyrocketing distance in narratives across the world.</li> </ol> <h5 id="post-ai-world-governance">Post-AI World Governance</h5> <ol> <li>What new global governance structures does the world need / how to adapt the existing structures to the contemporary and future contexts? a) The problem of old structures (e.g. World Bank, G7 summits, IMF) being inadequate to harness the emerging new global economy and technological age. i) The risks of perpetuating the essentially undemocratic and unequal character of these structures into AI governance b) The need for further creative destruction in the realm of intergovernmental institutions? c) What compromises would this require from the dominant powers? d) How to update international regulation? e) How can more policy transfers, and learnings, be facilitated across the world?</li> <li>What should the strategic partnerships with/among the Global South actors look like to encourage local adoption of AI?</li> <li>What should the national AI strategies look like in the Global South?</li> </ol> <h5 id="post-ai-world">Post-AI World</h5> <ol> <li>Impacts of AI on civil wars?</li> <li>What will post-AGI states look like? a) What will states need to survive? b) In what ways will the nation-state framework change? i) How can the increasing wealth and political power of the private sector undermine states’ sovereignty, monopoly on the use of violence, legitimacy, and role in service provision? ii) In what sense can AI-companies acquire state-like features? iii) How to increase the agility of nation-states / other governance structures to change according to the new environment and ideas at relatively low cost? iv) Questions about legitimacy transfers: from whom to whom?</li> <li>How will societies value individuals once labour is automated?</li> <li>What effects will automatisation have on human mental health?</li> <li>How could the unprecedented AI revolution exacerbate the centre-periphery power dynamics in global economics and politics?</li> </ol> <p>Big thanks to Herbie and Rudolf for their help and support with this exploration!</p>]]></content><author><name></name></author><category term="AI"/><summary type="html"><![CDATA[A list of key questions I collected between October 2023 and January 2024 after I decided to explore AI4D and global governance of AI.]]></summary></entry><entry><title type="html">New Global Governance Window: how the Global South can join the AI roundtable now.</title><link href="https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window/" rel="alternate" type="text/html" title="New Global Governance Window: how the Global South can join the AI roundtable now."/><published>2024-03-28T16:40:16+00:00</published><updated>2024-03-28T16:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window/"><![CDATA[<h4 id="abstract">Abstract</h4> <p>This essay draws attention of social policy scholars to the emerging global governance structures of Artificial Intelligence (AI) and their implications for the Global South. The current formation of the AI roundtable is dominated by Global North and risks perpetuating the Global South’s marginal position in global decision-making as well as depriving the capabilities of the Global Majority if governed by inadequate AI systems.</p> <p>Sen’s (1999) theory of development as freedom helps illustrate the potential social injustices and coupling of disadvantages among the Global South due to elite AI regulation and governance. Given these dangers, the essay draws on Kingdon’s (2011) multiple stream approach to policy-making and argues that the Global South can strengthen its engagement in AI global governance by seizing the “AI moment” and securing its seats at the AI roundtable. The recommendations include: (1) building coalitions, (2) investing in AI enablers and (3) actively participating in the emerging AI initiatives.</p> <h4 id="introduction">Introduction</h4> <p>Artificial Intelligence (AI) is an increasingly prominent instrument in international development, economic growth and in fact, everyday life. However, the design, deployment and regulation of that instrument are currently in the hands of a privileged few in the Global North, a label denoting the advantageous “political position in global power relations” (Freeman 2018:71). Global governance is a complex of formal and informal institutions which constitute sites of “wideranging processes of policy making across numerous issue areas that transcend national borders” (Davis 2012:272). AI is one of such essentially transnational issues, having cross-border effects and requiring a cross-border response. Yet, its arising elitist governance risks situating the Global South - that is, those at a marginal positionality in the global systems of decision-making (Freeman 2018) - in a place where the “Global Majority” (UN 2023) is governed by AI systems and regulations in which they had little or no say at all, perpetuating existing global inequalities (Obia 2023). Exclusion from participation in the making and regulating of systems that shape, often deterministically, people’s opportunities for their exercise of agency, constitutes a form of “unfreedom” in Sen’s (1999) terms. Therefore, drawing on Kingdon’s (2011) multiple streams approach to policy-making and Sen’s (1999) theory of development as freedoms advancing human capabilities, this essay draws attention to the currently forming global governance of AI as an emerging development issue for social policy experts to engage with. It addresses the question of how the Global South can strengthen its engagement in the emerging AI governance arguing that the Global Majority is facing a unique window of opportunity opened by the “AI moment” to secure their seats at the currently in-the-making AI roundtable. It then outlines potential policy recommendations for the Global South governmental and civil society actors on how to actually secure those seats, as well as it engages with challenges to seizing Kingdon’s (2011) opportunity window in the first place.</p> <h4 id="ai-moment">“AI moment”</h4> <p>The Organisation for Economic Cooperation and Development describes an AI system as “a machine-based system, that for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.” (OECD.AI 2023) In short, AI systems have generative powers increasingly affecting human environments and capabilities, which offers both hope and perils. In the context of international development, on one hand, Marwala (2019; 2023) argues optimistically for Africa embracing the Fourth Industrial Revolution and harnessing AI for accelerating the attainment of the already behind-schedule Sustainable Development Goals. AI seems to offer the tools for lifting the global poor from their multidimensional hardship through economic growth and increasing comforts of everyday life. On the other hand, AI carries risks of potentially grave economic consequences and social injustices if designed or regulated inadequately. Examples of the major sources for perpetuation of global inequalities through AI involve the insufficient diversity of datasets (Marwala et al. 2023) used for AI models training, or the unequal access to compute, which is the key part of building and deploying AI capacities (OECD 2023). The homogeneity of data can lead to bias propagations and compromising the effectiveness of AI systems, resulting in their poorer performance in the Global South (Marwala et al. 2023). Insufficient availability of data from the underrepresented contexts is one of the direct roots of this problem. There is also the risk of social injustice from inaction, that is, slowing down or preventing the use of available AI tools from, e.g. distributing essential vaccines or increasing the productivity of crops among the populations in need. While social policy experts have attemped work on data privacy issues (e.g. Sampath 2021) or AI model inclusiveness (e.g. Moon 2023, Adib-Moghaddam 2021), there is a significant gap in engaging with the emerging global governance structures of AI, a gap which this essay addresses.</p> <p>Given the wide range of potential perils, localised AI governance structures are being currently formed. Examples from 2023 include the UK AI Safety Summit, focused on identifying AI satefy risks and building respective risk-based policies; the United States Executive Order 14110 outlining Biden (2023) administration’s vision for harnessing AI for “justice, security, and opportunity for all”; or the European Union AI Act creating four risk categories of AI models and broad requirements for each one. On a more global level, the United Nations (UN) also convened a multi-stakeholder High-Level Advisory Body on AI to “undertake analysis and advance recommendations for the international governance of AI” (UN 2023:27). These initiatives are part of the “AI moment” where AI is an increasingly prioritised item on governmental and intergovernmental agendas, and where states are racing for leadership. The main penholders and agenda-setters behind these centralised structures are disproportionately located in Global North, dominating the AI roundtable which has not emerged in normative or institutional vacuum but within an already existing complex, unequal and contested site of international relations. The “AI divide is not separate from digital and developmental divides” (UN 2023:8), and the monoculture of knowledge, and priorities, risks perpetuating a structurally oppressive environment for the less represented but more vulnerable populations. AI is, therefore, not merely a technical tool, but in fact, it is an instrument of power and governance over which Global South should claim their share.</p> <h4 id="exclusive-ai-governance-as-a-source-of-unfreedom-and-capability-deprivation">Exclusive AI governance as a source of ‘unfreedom’ and capability deprivation</h4> <p>Sen’s (1999) approach to the essentially contested notion of development was formed in opposition to the more mainstream, yet narrower, views of development as GDP growth or industrialisation, which he sees as merely means to the actual goal of development. The real ends, he argues, are “expanding the real freedoms that people enjoy” (Sen 1999:3) and the removal of “unfreedoms that leave people with little choice and little opportunity of exercising their reasoned agency” (Sen 1999:xii). “Freedom is an inherently diverse concept” (Sen 1999:298), which implies the impossibility of a single, trans-contextual recipe for development. Some sources of ‘unfreedom’ identified by Sen (1999) are poverty, tyranny, or poor economic opportunities. Subjection to authoritative AI systems or exclusive governance structures producing unfavourable social arrangements complement the set.</p> <p>Sen (1999) distinguishes between instrumental and substantive freedoms, where the former advance the latter. “Human capabilities” are “the ability - the substantive freedom - of people to lead the lives they have reason to value and to enhance the real choices they have” (Sen 1999:293). He also emphasises that socio-political arrangements, the social ethics these arrangements produce and the environments of opportunties they create, heavily influence individuals’ capabilities. It is therefore not only the availability of alternatives but also the capacity to choose between them, and seize the ones that people value, which is core to Sen’s (1999) understanding of development. His work serves as a productive framework for analysing the relationship between AI arrangements and development, by examining the former’s impact on people’s choices, freedoms, and capabilities. The notion of capabilities can also be extrapolated from an individual to a state level, addressing the abilities of the Global South governments to harness AI for their specific priorities, sovereignty and self-determination in their national trajectories. Hence, it is being actively involved in the AI decision- and policy-making, not merely policy-taking, that seems essential for advancing development.</p> <p>However, the current domination of the AI roundtable by the Global North representatives risks harmful perpetuation of ‘unfreedoms’ and capability deprivation both on individual- and state-level among the underrepresented Global Majority. There is a significant divergence in priorities and capacities for how more and less advanced economies may wish to deploy AI systems. There is also a growing disparity in the narratives, where the Global North talks about preventing existential risks posed by highly advanced AI, and where parts of the Global South populations, especially in Sub-Saharan Africa, still lack the basic access to electricity which is essential for the activation of AI in the first place. There seems to be a need for an increased intersectional (Crenshaw 2019) sensitivity and negotiation in the AI sector in order to mitigate the effects of privileged origins of AI systems and regulations. The dangers range between relatively minor oppressions, such as the Google Maps not pronouncing well the names of local African routes (Marwala 2019:56), and more major violations, e.g. Chat GPT risks providing culturally homogenous answers, reproducing a kind of epistemological domination by “Western” sources. From a social justice perspective, inadequate attention to the diversity of contexts, human needs and preferences when advancing AI models or regulations, may translate into Global South communities “operating within rules that are externally set” (Obia 2023). This can altogether narrow people’s choices and limit their abilities to leverage AI for their own prosperity.</p> <p>More broadly, exclusive governance structures and the lack of participation in the discussions shaping the AI era undermine the capabilities of the Global South states, and other non-state actors, to represent, protect their populations and act in their interests. In fact, these capabilities are often already compromised given that, as Nicholls (2018) argues, 70-80% of the government’s power is determined by global power structures and only 20-30% is determined domestically. These numbers depict how institutions shape opportunities (Sen 1999). Being structurally disadvantageous in AI governance induces not only the immediate drawbacks of AI elitism but also the long-term perpetuation of essentially unequal world-order. The emergence of AI governance is not taking place in void, but rather, within already existing global inequalities and it risks coupling the political and economic disadvantages of Global South, deprivating its communities of capabilities to advance the lives they value. The magnitude of the subaltern condition (Spivak 1988) of the Global Majority risks being enhanced by exclusion from yet another key area of decision-making.</p> <p>There is also a grave conflict between the high rate of AI advancements and the lagging condition of their regulation, or adaptation to their new abilities. For a government to harness AI requires, therefore, to regulate the private sector, keep up with their new developments and possess the abilities to seize the inventions for desired outcomes. However, few countries actually meet all of these three criteria, and even if they do, the actual benefit from AI might in fact be unequally distributed within them as well. The influence and rate of multisector development might grow disproportionately across global populations, continuing the centralisation of the world’s wealth in Global North and a comparative underdevelopment of those areas that are not able to harness AI for their own growth. Global South may see ensuring equitable global governance of AI as an instrument for “correcting the international inequalities and promoting convergence among countries” (Ocampo 2016:131).</p> <h4 id="seizing-the-ai-global-governance-window">Seizing the AI Global Governance Window</h4> <p>This essay proposes that amidst the current “AI moment”, Global South is in fact facing a unique window of opportunity to ensure more equitable global governance of AI by establishing its representation at the emerging AI roundtable, and as a result, limiting the potential ‘unfreedoms’ from inadequate AI systems and regulations.</p> <p>Kingdon’s (2011:165) multiple stream approach to policy-making outlines that a policy window is “an opportunity for advocates of proposals to push their pet solutions, or to push attention to their special problems”. It opens when the three “separate streams (…) come together and are coupled” (Kingdon 2011:166), that is: the problem is clearly defined, the political will for change is present, and a feasible solution is available. Kingdon (2011) also stresses that windows of opportunity are infrequent, short and mostly unpredictable, with the exception of cyclical windows, such as budgetary renewals. Yet, policy-making is usually not as clear and rational of a process as assumed by Kingdon (2011) who Howlett et al. (2015:1) criticised for “lacking political realism”. The conditions of randomness, dynamism and complexity might influence the convergence of readiness of the three streams. What’s more, despite the multiple stream approach being developed in a rather national context of policy-making, and its “application to the global level” being “still rare” (Jakobsson 2021:7), it nevertheless, acts as a productive lens for analysing how and when Global South might claim its position in AI governance more effectively.</p> <p>In mid-2023 Obia (2023) argued that “the window for such an Africa-inclusive [AI] protocol may well be closing fast”; a protocol not to govern over the Global Majority with AI, but to govern AI with them. It is a window to bring more attention, both in public and private sectors, to the necessity for Global South engagement and to implement adequate policies. The problem of Global South exclusion seems increasingly well defined with the recent publications of the UN (2023) “Interim Report: Governing AI for Humanity” and independent AI research centers prompting the conversation as well. The political will to engage in those discussions seems equally present, e.g. the UN is currently calling on experts to help design global governance structures for AI in their final 2024 report, and AI is undeniably a more prominent theme on governments’ “decision agendas”, “a smaller set of items that is being decided upon” (Kingdon 2011:166) with higher priority. However, willingness to engage in conversations does not necessarily transfer to implementing the recommendations, and it is here that the Global South might need to exert particular pressure. Solutions for equitable AI governance exist to a lesser degree than required by Kingdon (2011). It is not yet clear what Global South involvement could and should look like exactly. The risk is, however, that the already existing multilateral institutions such as the UN or the World Trade Organisation might serve as uncontested examples to follow, where in fact, they are often criticised for being far from democratic and fair (Zürn 2004).</p> <p>It seems necessary to increase the availability of feasible alternatives on how the currently emerging and therefore, still fairly malleable, AI governance initiatives can engage the Global South. This task calls for more policy entrepreneurs, that is the “advocates who are willing to invest their resources - time, energy, reputation, money - to promote a position” (Kingdon 2011:179). It is a unique time to act as it is the beginning of shaping AI structures and a moment that will give momentum to the trajectories of the AI divide. The opportunity to influence the overarching discourse and principles of these governing structures may pass, with future windows of opportunity being possibly narrower and more limited in their scope for change given the resistance to fundamental shifts in established institutions and more constrained future sets of choice, according to the path dependency theory (North 1990). Once Global South exclusion from AI decision-making becomes just another condition of global governance, rather than still an active problem, the less likely it is to enter the “decision agendas” again (Kingdon 2011).</p> <p>Policy reform is a process (Grindle and Thomas 1990), not an event. Therefore, it is important to bear in mind the essentially interactive and contested nature of policy-making. Here are brief examples of ideal-type paths forward for the Global South governmental and civil society actors on how to seize the “AI moment” and ensure their seat at the AI roundtable:</p> <p>Build coalitions. To effectively navigate through the asymmetric power dynamics on the global stage, less powerful states may benefit from collaboration on achieving regional objectives. Firstly, technology offers the global poor an instrument for alleviating their hardship. Thus, Marwala (2019) emphasises the need for African leaders to harness the understanding of AI and realise its potential. These leaders could also become public “problem brokers” (Knaggard 2015) strengthening the narrative frame of the problem of exclusion and together create more pressure for the Global North AI governance initiatives to enhance their engagement. Secondly, Global South would benefit from addressing the aforementioned gap in social policy research on how to build fair, accoutable and transparent (UN 2023) AI governance structures that strengthen people’s freedoms and capabilities (Sen 1999), and on what exactly a desirable AI agenda for the Global Majority would look like.</p> <p>Invest in enablers. Influence from AI depends on the availability of “enablers” (UN 2023:6), e.g. talent pools, data, compute and infrastructure. Investing in these areas and increasing AI capacities among the Global South states may be especially beneficial long-term. For example, increasing AI expertise can boost employment rates as AI offers to reshuffle labour-markets. Similarly, Marwala (2019:57) argues that Africa ought to follow India’s National Strategy for AI and “transform itself into an innovative hi-tech powerhouse”.</p> <p>Participate. Obia (2023) calls for strengthening African Union advocacy for “inclusivity in the development of general purpose AI regulation”. In fact, to add Global South lenses to AI talks and ensure a more intersectional representation of interests, there is a role to play not only by governments but also civil society, the ultimate recipients of AI systems. The UN AI Advisory Body (2023:24) is currently open for consultations, “look[ing] forward to engaging with diverse stakeholders” and together shaping the vision for AI global governance. Furthermore, staying in the information loop and engaging in knowledge sharing on AI, e.g. at events such as the AI Safety Summits, can help Global South transition from passive policy recipient to a technological partner, one that also has the decision-making power to avert unfavourable regulations.</p> <h4 id="challenges-to-kingdons-approach">Challenges to Kingdon’s approach</h4> <p>In respect to Kingdon’s theory (2011), the essay risks being overconfident in arguing for an existence of a window of opportunity for Global South engagement offered by the “AI moment”. Yet, its call for more social policy research on AI global governance structures and regulations holds given its evident insufficiency, and the high significance of AI for development. It may be that through problem brokering and policy entrepreneurship, the Global South can either open or widen such a window, seizing it with the newly developed alternatives for AI global governance.</p> <p>However, there remains the challenging nature of global governance itself: a “lack of consensus” as its “inherent characteristic” (Pouliot and Thérien 2023:14) and a high level of uncertainty posed by fast developments in AI which complicates the decision-making processes. The Global North has strong interests in elite AI governance, prioritising, therefore, efficiency over equity. Furthemore, the Global South has already formed coalitions aimed at rebalancing power relations in multilateral institutions in the past, with little success. For example, Freeman (2018:78) depicts how since 1960s, the Group of Seventy Seven, a political bloc formed by Global South leaders in the UN, have “called for an ‘international enabling environment’ for development”, asking for more democratic and representative global governance arrangements, and for an equal voice in intergovernmental organisations. Yet, their limited success is mirrored in the lack of substantial changes to institutional arrangements of the UN or the decision-making power distribution.</p> <p>Finally, there is no singular Global South, but a multitude of marginally positioned entities in global power relations. Overestimating regional homogeneities risk “overgeneralising” (Sen 2001) populations and suppressing intersectionally vulnerable voices. Inclusive governance, therefore, is not necessarily about having “everyone at the table” but “having the right mix” (Chatham House 2021), which social policy research could contribute significantly to identifying. There is a conflict between the sheer diveristy in agendas and the need for relative unity to advance broader Global South interests in global governance of AI. Coalitions, therefore, might be effective for a limited period of time, as different trajectories of their members can make holding together less possible with time.</p> <h4 id="conclusion">Conclusion</h4> <p>Departing from the relationship between governing structures and development capabilities drawing on Sen’s (1999) work, and the risks posed by the emerging elitist AI regulations, this essay addressed the question of how Global South can strengthen their engagement in the global governance of AI. It built on Kingdon’s (2011) theory of policy windows to argue for the current convergence of problem definition, political will and available solutions, and consequently, for seizing that window to claim Global South seats at the AI roundtable. The proposed strategies included (1) building a coalition among Global South entities to advance common interests more effectively at the exisiting AI governance initiatives; (2) investing in AI talent, compute and data collection to equip the Global Majority with enablers for technological advancements; (3) participating in shaping the ongoing discussions on AI regulation both by Global South governmental and civil society actors to represent a broader spectrum of interests. This essay also aimed at addressing the existing gap in social policy research on governance of AI. Excluding the Global Majority from AI talks may lead to magnified levels of global inequalities by coupling economic and political disadvantages of Global South, and depriving individuals of capabilities for pursuing lives they value. Measuring AI governance success should be conditional on an active global participation. Still, there remain many more research puzzles to be tackled that social policy could heavily contribute to such as designing data governance or preventing global wealth concentration in the hands of a few AI companies.</p> <hr/> <h4 id="references">References</h4> <p>Adib-Moghaddam , A. (2023). Is Artificial Intelligence Racist? The Ethics of AI and the Future of Humanity. London: Bloomsbury Publishing.</p> <p>Biden, J. (2023). Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. [online] The White House. Available at: https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/ [Accessed 16 Jan. 2024].</p> <p>Chatham House (2021). Reflections on building more inclusive global governance. [online] Chatham House. Available at: https://www.chathamhouse.org/2021/04/reflections-building-more-inclusive-global-governance [Accessed 16 Jan. 2024].</p> <p>Crenshaw, K. (2019). On intersectionality: Essential writings. New York, NY: The New Press.</p> <p>Davis, J. (2012). Swiss Political Science Review Swiss Political Science Review Free Access A Critical View of Global Governance. Swiss Political Science Review, (18), pp.272–286.</p> <p>Freeman, D. (2018). The Global South at the UN: using international politics to re-vision the global. The Global South, (11), pp.71–91.</p> <p>Grindle, M. and Thomas, J. (1990) After the Decision: Implementing Policy Reforms in Developing Countries. World Development. Vol. 18 (8)</p> <p>Howlett, M., McConnel, A. and Perl, A. (2015). Streams and stages: Reconciling Kingdon and policy process theory. European Journal of Political Research, 54(3), pp.419–434.</p> <p>Jakobsson, E. (2021). How Climate-Induced Migration Entered the UN Policy Agenda in 2007–2010: A Multiple Streams Assessment. Politics and Governance, 9(4), pp.16–26.</p> <p>Kingdon (2011). Agendas, Alternatives, and Public Policies. 2nd ed. Boston: Longman. [1984]</p> <p>Knaggard, A. (2015). The Multiple Streams Framework and the problem broker. European Journal of Political Research, 54(3), pp.450–465.</p> <p>Marwala, T. (2019). Artificial intelligence, at Africa’s door. The UNESCO Courier, 2019(2), pp.56–57.</p> <p>Marwala, T., Fournier-Tombs, E. and Stinckwich, S. (2023). The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development. [online] United Nations University . Available at: https://unu.edu/publication/use-synthetic-data-train-ai-models-opportunities-and-risks-sustainable-development [Accessed 16 Jan. 2024].</p> <p>Moon, M. (2023). Searching for inclusive artificial intelligence for social good: Participatory governance and policy recommendations for making AI more inclusive and benign for society. Public Administration Review, 83(6), pp.1496–1505.</p> <p>Nicholls, E. (2018). Studying the state: a Global South perspective. Third World Thematics: A TWQ Journal, 3(4), pp.469–478.</p> <p>North, D. (1990). Institutions, Institutional Change and Economic Performance. Cambridge: Cambridge University Press.</p> <p>Obia, V. (2023). What can African countries do to regulate artificial intelligence? [online] London School of Economics and Political Science.</p> <p>Ocampo, J. (2016). Global Governance and Development. Oxford: Oxford University Press.</p> <p>OECD (2023), “A blueprint for building national compute capacity for artificial intelligence”, OECD Digital Economy Papers, No. 350, OECD Publishing, Paris.</p> <p>OECD.AI. (2023). Updates to the OECD’s definition of an AI system explained. [online] Available at: https://oecd.ai/en/wonk/ai-system-definition-update [Accessed 16 Jan. 2024].</p> <p>Pouliot, V. and Thérien, J-P. (2023). Introduction: The Politics of Global Governance. In: Global Policymaking: The Patchwork of Global Governance. Cambridge: Cambridge University Press, pp.1–21.</p> <p>Sampath, P. (2021). Governing Artificial Intelligence in an Age of Inequality. Global Policy, 12(S6), pp.21–31.</p> <p>Sen, A. (1999). Development as Freedom. New York: Alfred A. Knopf, Inc.</p> <p>Sen, A. (2001). A World Not Neatly Divided. [online] New York Times. Available at: https://www.nytimes.com/2001/11/23/opinion/a-world-not-neatly-divided.html [Accessed 16 Jan. 2024].</p> <p>Spivak, G. (1988). Can the Subaltern Speak? Die Philosophin, 14(27), pp.42–58.</p> <p>Toye, J. (2014). Assessing the G77: 50 years after UNCTAD and 40 years after the NIEO. Third World Quarterly, 35(10), pp.1759–1774.</p> <p>United Nations. (2023). Interim Report: Governing AI for Humanity. [online] Available at: https://www.un.org/en/ai-advisory-body [Accessed 16 Jan. 2024].</p> <p>Zürn, M. (2004). Global Governance and Legitimacy Problems. Government and Opposition, 39(2), pp.260–287.</p>]]></content><author><name></name></author><category term="international-development"/><category term="AI"/><summary type="html"><![CDATA[An introductory essay I wrote for my Social Policy in Development course at LSE. I draw on Sen's and Kingdon's theories to explore why exclusive AI governance may have detrimental effects on the global poor.]]></summary></entry></feed>