<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://joannawiaterek.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://joannawiaterek.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-24T16:10:03+00:00</updated><id>https://joannawiaterek.github.io/feed.xml</id><title type="html">Joanna Wiaterek</title><subtitle>Hi, this is Asia. I am a social anthropologist interested in global development, global governance of AI and benefit-sharing. I have lots of questions about effective aid, innovation and inequality, and the impact of AI on the global order. I did my undergrad at Cambridge in Human, Social and Political Sciences. Recently, I have finished my Masters at LSE where I wrote my dissertation on the inclusivity of the UN AI governance. Currently, I am co-founding the [Equiano Institute](https://www.equiano.institute/) where we research societal impacts of AI with a particulat focus on developing countries. In a different life I would probably be a theatre actress. I love sports, cooking and learning foreign languages. Get in touch!&gt;</subtitle><entry><title type="html">Global Governance of AI: preliminary questions</title><link href="https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI/" rel="alternate" type="text/html" title="Global Governance of AI: preliminary questions"/><published>2024-03-28T16:40:16+00:00</published><updated>2024-03-28T16:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2024/Global-Governance-of-AI/"><![CDATA[<p>Last update: 17/1/2024</p> <h4 id="context">Context</h4> <p>Most discussions surrounding AI are relatively recent and still highly neglected. Yet, when it comes to the questions related to AI and the Global South, especially, AI-related implications on the global economic and political order, the space seems even more overlooked.</p> <p>There are four key aspects to distinguish:</p> <ol> <li>Design of AI systems (e.g. Who is included in designing and regulating the AI models (compute, data, expertise)?)</li> <li>Bridging the AI divide (e.g. How to advance technological capabilities and independence among the Global South actors?)</li> <li>Global Governance of AI (e.g. What should inclusive institutions look like to ensure benefit-sharing?)</li> <li>Post-A(G)I World Order (e.g. Who has access to the emerging AI models and abilities to harness them? What will the impacts be of e.g. AI automation, AI-generated wealth, on the existing global economic and political order?)</li> </ol> <p>There is an urgent need for a more widespread debate on the global implications of AI, its feasible and equitable governance structures, and ensuring a fair global AI regulation system before it is too late.</p> <h4 id="problem">Problem</h4> <p>The existing work on the impacts of AI automation or regulation is highly localised, predominantly referring to the so-called “Global North” countries (e.g. <a href="https://philiptrammell.com/static/economic_growth_under_transformative_ai.pdf">Trammel and Korinek 2023</a>). In fact, most of the “discussion about the consequences and regulation of AI is occurring among countries whose populations make up just 1.3 billion people” (<a href="https://foreignpolicy.com/2023/05/29/ai-regulation-global-south-artificial-intelligence/">Muggah and Carvalho 2023</a>). What about the Global Majority?</p> <p>The implications of any major innovation are inescapably global and so the innovations in question require a global, collaborative approach.</p> <p>It is critical to expand the AI debate beyond the national concerns of the Global North and to address the world-scale questions concerning issues including the risks from AI in widening global income inequality, the potential challenges of AI to the current political structures, or perpetuation of existing global injustices and structural imbalances through the AI systems (<a href="https://www.soas.ac.uk/study/blog/how-can-ai-better-serve-people-global-south">Batabyal 2023</a>). The world as a whole needs a more cooperative design of AI governance (e.g., <a href="https://www.governance.ai/post/the-case-for-including-the-global-south-in-ai-governance-conversations">Adan 2023</a>, <a href="https://blogs.lse.ac.uk/medialse/2023/06/13/what-can-african-countries-do-to-regulate-artificial-intelligence/">Obia 2023</a>), and ensuring favourable effects from AI on global welfare, especially for the world’s poorest.</p> <hr/> <h4 id="questions">Questions</h4> <h5 id="global-southaiequity">Global South/AI/Equity</h5> <ol> <li>What aspects of AI could specific Global South actors become leaders in? What makes them suitable leaders? How to seize that leadership? Long-term effects of that leadership?</li> <li>What are the unobvious, yet potentially highly effective South-South and North-South coalition in AI governance?</li> <li>How to ensure that Africa has at least a fair start to the AI-related opportunities for economic growth, increase in average welfare, and AI regulations? a) What could multi-stakeholder and benefit-sharing regulations look like? b) When will the window of opportunity close? c) Questions of data abuse? d) How to avoid AI being merely another instrument of the Global North domination, but include the Global South in the “AI lifecycle” (<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/puar.13648">Moon 2023</a>)?</li> <li>How to achieve AI equity if the world is still suffering from unequal access to previous innovations, such as electricity or the Internet? a) How will different countries benefit unequally from AI? What implications will this inequality have? b) How to avoid further concentration of wealth and knowledge? What implications could such concentrated accumulation of technologies have on world poverty and inequality? c) Are there any possibilities for less-developed countries to benefit from not being limited by existing infrastructure / regulations / etc.? (e.g. bypassing centralised fossil fuel-powered electric grids entirely by some countries and going straight to distributed renewable-based electric grids)</li> </ol> <h5 id="ai--eradication-of-global-poverty">AI &amp; Eradication of Global Poverty</h5> <ol> <li>What are the “best buys” in AI4D? a) What evidence is lacking?</li> <li>How to bridge the global AI divide? a) What role can foreign aid play here? b) How to foster technological independence?</li> <li>What global inequalities can AI generate/exacerbate? a) What structural inequalities will be exacerbated? What about the coupling of past, current and future inequalities?</li> <li>How to leverage the AI potential to eradicate extreme poverty and raise the bottom tail of the global income distribution to a fruitful living standard, simultaneously controlling the potential expansive inequality growth? a) What system/regulation would have to be in place to create a kind of global, social protection in order to ensure the poorest are not left behind?</li> <li>Is there an emerging role for the private sector to eradicate extreme poverty and raise the GDP of the Global South?</li> <li>Are the global poor going to have a good, flourishing life in a post-AI world? a) Will the global poor play any role in the critical inputs to AI systems (compute, data, talent, experts implementing algorithms)?</li> <li>What could a global social protection system look like to mitigate the AI-crises [e.g. wealth inequality, existential threats]?</li> <li>How out of touch from one another are the states (increasingly) becoming? The skyrocketing distance in narratives across the world.</li> </ol> <h5 id="post-ai-world-governance">Post-AI World Governance</h5> <ol> <li>What new global governance structures does the world need / how to adapt the existing structures to the contemporary and future contexts? a) The problem of old structures (e.g. World Bank, G7 summits, IMF) being inadequate to harness the emerging new global economy and technological age. i) The risks of perpetuating the essentially undemocratic and unequal character of these structures into AI governance b) The need for further creative destruction in the realm of intergovernmental institutions? c) What compromises would this require from the dominant powers? d) How to update international regulation? e) How can more policy transfers, and learnings, be facilitated across the world?</li> <li>What should the strategic partnerships with/among the Global South actors look like to encourage local adoption of AI?</li> <li>What should the national AI strategies look like in the Global South?</li> </ol> <h5 id="post-ai-world">Post-AI World</h5> <ol> <li>Impacts of AI on civil wars?</li> <li>What will post-AGI states look like? a) What will states need to survive? b) In what ways will the nation-state framework change? i) How can the increasing wealth and political power of the private sector undermine states’ sovereignty, monopoly on the use of violence, legitimacy, and role in service provision? ii) In what sense can AI-companies acquire state-like features? iii) How to increase the agility of nation-states / other governance structures to change according to the new environment and ideas at relatively low cost? iv) Questions about legitimacy transfers: from whom to whom?</li> <li>How will societies value individuals once labour is automated?</li> <li>What effects will automatisation have on human mental health?</li> <li>How could the unprecedented AI revolution exacerbate the centre-periphery power dynamics in global economics and politics?</li> </ol> <p>Big thanks to Herbie and Rudolf for their help and support with this exploration!</p>]]></content><author><name></name></author><category term="AI"/><summary type="html"><![CDATA[A list of key questions I collected between October 2023 and January 2024 after I decided to explore AI4D and global governance of AI.]]></summary></entry><entry><title type="html">New Global Governance Window: how the Global South can join the AI roundtable now.</title><link href="https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window/" rel="alternate" type="text/html" title="New Global Governance Window: how the Global South can join the AI roundtable now."/><published>2024-03-28T16:40:16+00:00</published><updated>2024-03-28T16:40:16+00:00</updated><id>https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window</id><content type="html" xml:base="https://joannawiaterek.github.io/blog/2024/New-Global-Governance-Window/"><![CDATA[<h4 id="abstract">Abstract</h4> <p>This essay draws attention of social policy scholars to the emerging global governance structures of Artificial Intelligence (AI) and their implications for the Global South. The current formation of the AI roundtable is dominated by Global North and risks perpetuating the Global South’s marginal position in global decision-making as well as depriving the capabilities of the Global Majority if governed by inadequate AI systems.</p> <p>Sen’s (1999) theory of development as freedom helps illustrate the potential social injustices and coupling of disadvantages among the Global South due to elite AI regulation and governance. Given these dangers, the essay draws on Kingdon’s (2011) multiple stream approach to policy-making and argues that the Global South can strengthen its engagement in AI global governance by seizing the “AI moment” and securing its seats at the AI roundtable. The recommendations include: (1) building coalitions, (2) investing in AI enablers and (3) actively participating in the emerging AI initiatives.</p> <h4 id="introduction">Introduction</h4> <p>Artificial Intelligence (AI) is an increasingly prominent instrument in international development, economic growth and in fact, everyday life. However, the design, deployment and regulation of that instrument are currently in the hands of a privileged few in the Global North, a label denoting the advantageous “political position in global power relations” (Freeman 2018:71). Global governance is a complex of formal and informal institutions which constitute sites of “wideranging processes of policy making across numerous issue areas that transcend national borders” (Davis 2012:272). AI is one of such essentially transnational issues, having cross-border effects and requiring a cross-border response. Yet, its arising elitist governance risks situating the Global South - that is, those at a marginal positionality in the global systems of decision-making (Freeman 2018) - in a place where the “Global Majority” (UN 2023) is governed by AI systems and regulations in which they had little or no say at all, perpetuating existing global inequalities (Obia 2023). Exclusion from participation in the making and regulating of systems that shape, often deterministically, people’s opportunities for their exercise of agency, constitutes a form of “unfreedom” in Sen’s (1999) terms. Therefore, drawing on Kingdon’s (2011) multiple streams approach to policy-making and Sen’s (1999) theory of development as freedoms advancing human capabilities, this essay draws attention to the currently forming global governance of AI as an emerging development issue for social policy experts to engage with. It addresses the question of how the Global South can strengthen its engagement in the emerging AI governance arguing that the Global Majority is facing a unique window of opportunity opened by the “AI moment” to secure their seats at the currently in-the-making AI roundtable. It then outlines potential policy recommendations for the Global South governmental and civil society actors on how to actually secure those seats, as well as it engages with challenges to seizing Kingdon’s (2011) opportunity window in the first place.</p> <h4 id="ai-moment">“AI moment”</h4> <p>The Organisation for Economic Cooperation and Development describes an AI system as “a machine-based system, that for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.” (OECD.AI 2023) In short, AI systems have generative powers increasingly affecting human environments and capabilities, which offers both hope and perils. In the context of international development, on one hand, Marwala (2019; 2023) argues optimistically for Africa embracing the Fourth Industrial Revolution and harnessing AI for accelerating the attainment of the already behind-schedule Sustainable Development Goals. AI seems to offer the tools for lifting the global poor from their multidimensional hardship through economic growth and increasing comforts of everyday life. On the other hand, AI carries risks of potentially grave economic consequences and social injustices if designed or regulated inadequately. Examples of the major sources for perpetuation of global inequalities through AI involve the insufficient diversity of datasets (Marwala et al. 2023) used for AI models training, or the unequal access to compute, which is the key part of building and deploying AI capacities (OECD 2023). The homogeneity of data can lead to bias propagations and compromising the effectiveness of AI systems, resulting in their poorer performance in the Global South (Marwala et al. 2023). Insufficient availability of data from the underrepresented contexts is one of the direct roots of this problem. There is also the risk of social injustice from inaction, that is, slowing down or preventing the use of available AI tools from, e.g. distributing essential vaccines or increasing the productivity of crops among the populations in need. While social policy experts have attemped work on data privacy issues (e.g. Sampath 2021) or AI model inclusiveness (e.g. Moon 2023, Adib-Moghaddam 2021), there is a significant gap in engaging with the emerging global governance structures of AI, a gap which this essay addresses.</p> <p>Given the wide range of potential perils, localised AI governance structures are being currently formed. Examples from 2023 include the UK AI Safety Summit, focused on identifying AI satefy risks and building respective risk-based policies; the United States Executive Order 14110 outlining Biden (2023) administration’s vision for harnessing AI for “justice, security, and opportunity for all”; or the European Union AI Act creating four risk categories of AI models and broad requirements for each one. On a more global level, the United Nations (UN) also convened a multi-stakeholder High-Level Advisory Body on AI to “undertake analysis and advance recommendations for the international governance of AI” (UN 2023:27). These initiatives are part of the “AI moment” where AI is an increasingly prioritised item on governmental and intergovernmental agendas, and where states are racing for leadership. The main penholders and agenda-setters behind these centralised structures are disproportionately located in Global North, dominating the AI roundtable which has not emerged in normative or institutional vacuum but within an already existing complex, unequal and contested site of international relations. The “AI divide is not separate from digital and developmental divides” (UN 2023:8), and the monoculture of knowledge, and priorities, risks perpetuating a structurally oppressive environment for the less represented but more vulnerable populations. AI is, therefore, not merely a technical tool, but in fact, it is an instrument of power and governance over which Global South should claim their share.</p> <h4 id="exclusive-ai-governance-as-a-source-of-unfreedom-and-capability-deprivation">Exclusive AI governance as a source of ‘unfreedom’ and capability deprivation</h4> <p>Sen’s (1999) approach to the essentially contested notion of development was formed in opposition to the more mainstream, yet narrower, views of development as GDP growth or industrialisation, which he sees as merely means to the actual goal of development. The real ends, he argues, are “expanding the real freedoms that people enjoy” (Sen 1999:3) and the removal of “unfreedoms that leave people with little choice and little opportunity of exercising their reasoned agency” (Sen 1999:xii). “Freedom is an inherently diverse concept” (Sen 1999:298), which implies the impossibility of a single, trans-contextual recipe for development. Some sources of ‘unfreedom’ identified by Sen (1999) are poverty, tyranny, or poor economic opportunities. Subjection to authoritative AI systems or exclusive governance structures producing unfavourable social arrangements complement the set.</p> <p>Sen (1999) distinguishes between instrumental and substantive freedoms, where the former advance the latter. “Human capabilities” are “the ability - the substantive freedom - of people to lead the lives they have reason to value and to enhance the real choices they have” (Sen 1999:293). He also emphasises that socio-political arrangements, the social ethics these arrangements produce and the environments of opportunties they create, heavily influence individuals’ capabilities. It is therefore not only the availability of alternatives but also the capacity to choose between them, and seize the ones that people value, which is core to Sen’s (1999) understanding of development. His work serves as a productive framework for analysing the relationship between AI arrangements and development, by examining the former’s impact on people’s choices, freedoms, and capabilities. The notion of capabilities can also be extrapolated from an individual to a state level, addressing the abilities of the Global South governments to harness AI for their specific priorities, sovereignty and self-determination in their national trajectories. Hence, it is being actively involved in the AI decision- and policy-making, not merely policy-taking, that seems essential for advancing development.</p> <p>However, the current domination of the AI roundtable by the Global North representatives risks harmful perpetuation of ‘unfreedoms’ and capability deprivation both on individual- and state-level among the underrepresented Global Majority. There is a significant divergence in priorities and capacities for how more and less advanced economies may wish to deploy AI systems. There is also a growing disparity in the narratives, where the Global North talks about preventing existential risks posed by highly advanced AI, and where parts of the Global South populations, especially in Sub-Saharan Africa, still lack the basic access to electricity which is essential for the activation of AI in the first place. There seems to be a need for an increased intersectional (Crenshaw 2019) sensitivity and negotiation in the AI sector in order to mitigate the effects of privileged origins of AI systems and regulations. The dangers range between relatively minor oppressions, such as the Google Maps not pronouncing well the names of local African routes (Marwala 2019:56), and more major violations, e.g. Chat GPT risks providing culturally homogenous answers, reproducing a kind of epistemological domination by “Western” sources. From a social justice perspective, inadequate attention to the diversity of contexts, human needs and preferences when advancing AI models or regulations, may translate into Global South communities “operating within rules that are externally set” (Obia 2023). This can altogether narrow people’s choices and limit their abilities to leverage AI for their own prosperity.</p> <p>More broadly, exclusive governance structures and the lack of participation in the discussions shaping the AI era undermine the capabilities of the Global South states, and other non-state actors, to represent, protect their populations and act in their interests. In fact, these capabilities are often already compromised given that, as Nicholls (2018) argues, 70-80% of the government’s power is determined by global power structures and only 20-30% is determined domestically. These numbers depict how institutions shape opportunities (Sen 1999). Being structurally disadvantageous in AI governance induces not only the immediate drawbacks of AI elitism but also the long-term perpetuation of essentially unequal world-order. The emergence of AI governance is not taking place in void, but rather, within already existing global inequalities and it risks coupling the political and economic disadvantages of Global South, deprivating its communities of capabilities to advance the lives they value. The magnitude of the subaltern condition (Spivak 1988) of the Global Majority risks being enhanced by exclusion from yet another key area of decision-making.</p> <p>There is also a grave conflict between the high rate of AI advancements and the lagging condition of their regulation, or adaptation to their new abilities. For a government to harness AI requires, therefore, to regulate the private sector, keep up with their new developments and possess the abilities to seize the inventions for desired outcomes. However, few countries actually meet all of these three criteria, and even if they do, the actual benefit from AI might in fact be unequally distributed within them as well. The influence and rate of multisector development might grow disproportionately across global populations, continuing the centralisation of the world’s wealth in Global North and a comparative underdevelopment of those areas that are not able to harness AI for their own growth. Global South may see ensuring equitable global governance of AI as an instrument for “correcting the international inequalities and promoting convergence among countries” (Ocampo 2016:131).</p> <h4 id="seizing-the-ai-global-governance-window">Seizing the AI Global Governance Window</h4> <p>This essay proposes that amidst the current “AI moment”, Global South is in fact facing a unique window of opportunity to ensure more equitable global governance of AI by establishing its representation at the emerging AI roundtable, and as a result, limiting the potential ‘unfreedoms’ from inadequate AI systems and regulations.</p> <p>Kingdon’s (2011:165) multiple stream approach to policy-making outlines that a policy window is “an opportunity for advocates of proposals to push their pet solutions, or to push attention to their special problems”. It opens when the three “separate streams (…) come together and are coupled” (Kingdon 2011:166), that is: the problem is clearly defined, the political will for change is present, and a feasible solution is available. Kingdon (2011) also stresses that windows of opportunity are infrequent, short and mostly unpredictable, with the exception of cyclical windows, such as budgetary renewals. Yet, policy-making is usually not as clear and rational of a process as assumed by Kingdon (2011) who Howlett et al. (2015:1) criticised for “lacking political realism”. The conditions of randomness, dynamism and complexity might influence the convergence of readiness of the three streams. What’s more, despite the multiple stream approach being developed in a rather national context of policy-making, and its “application to the global level” being “still rare” (Jakobsson 2021:7), it nevertheless, acts as a productive lens for analysing how and when Global South might claim its position in AI governance more effectively.</p> <p>In mid-2023 Obia (2023) argued that “the window for such an Africa-inclusive [AI] protocol may well be closing fast”; a protocol not to govern over the Global Majority with AI, but to govern AI with them. It is a window to bring more attention, both in public and private sectors, to the necessity for Global South engagement and to implement adequate policies. The problem of Global South exclusion seems increasingly well defined with the recent publications of the UN (2023) “Interim Report: Governing AI for Humanity” and independent AI research centers prompting the conversation as well. The political will to engage in those discussions seems equally present, e.g. the UN is currently calling on experts to help design global governance structures for AI in their final 2024 report, and AI is undeniably a more prominent theme on governments’ “decision agendas”, “a smaller set of items that is being decided upon” (Kingdon 2011:166) with higher priority. However, willingness to engage in conversations does not necessarily transfer to implementing the recommendations, and it is here that the Global South might need to exert particular pressure. Solutions for equitable AI governance exist to a lesser degree than required by Kingdon (2011). It is not yet clear what Global South involvement could and should look like exactly. The risk is, however, that the already existing multilateral institutions such as the UN or the World Trade Organisation might serve as uncontested examples to follow, where in fact, they are often criticised for being far from democratic and fair (Zürn 2004).</p> <p>It seems necessary to increase the availability of feasible alternatives on how the currently emerging and therefore, still fairly malleable, AI governance initiatives can engage the Global South. This task calls for more policy entrepreneurs, that is the “advocates who are willing to invest their resources - time, energy, reputation, money - to promote a position” (Kingdon 2011:179). It is a unique time to act as it is the beginning of shaping AI structures and a moment that will give momentum to the trajectories of the AI divide. The opportunity to influence the overarching discourse and principles of these governing structures may pass, with future windows of opportunity being possibly narrower and more limited in their scope for change given the resistance to fundamental shifts in established institutions and more constrained future sets of choice, according to the path dependency theory (North 1990). Once Global South exclusion from AI decision-making becomes just another condition of global governance, rather than still an active problem, the less likely it is to enter the “decision agendas” again (Kingdon 2011).</p> <p>Policy reform is a process (Grindle and Thomas 1990), not an event. Therefore, it is important to bear in mind the essentially interactive and contested nature of policy-making. Here are brief examples of ideal-type paths forward for the Global South governmental and civil society actors on how to seize the “AI moment” and ensure their seat at the AI roundtable:</p> <p>Build coalitions. To effectively navigate through the asymmetric power dynamics on the global stage, less powerful states may benefit from collaboration on achieving regional objectives. Firstly, technology offers the global poor an instrument for alleviating their hardship. Thus, Marwala (2019) emphasises the need for African leaders to harness the understanding of AI and realise its potential. These leaders could also become public “problem brokers” (Knaggard 2015) strengthening the narrative frame of the problem of exclusion and together create more pressure for the Global North AI governance initiatives to enhance their engagement. Secondly, Global South would benefit from addressing the aforementioned gap in social policy research on how to build fair, accoutable and transparent (UN 2023) AI governance structures that strengthen people’s freedoms and capabilities (Sen 1999), and on what exactly a desirable AI agenda for the Global Majority would look like.</p> <p>Invest in enablers. Influence from AI depends on the availability of “enablers” (UN 2023:6), e.g. talent pools, data, compute and infrastructure. Investing in these areas and increasing AI capacities among the Global South states may be especially beneficial long-term. For example, increasing AI expertise can boost employment rates as AI offers to reshuffle labour-markets. Similarly, Marwala (2019:57) argues that Africa ought to follow India’s National Strategy for AI and “transform itself into an innovative hi-tech powerhouse”.</p> <p>Participate. Obia (2023) calls for strengthening African Union advocacy for “inclusivity in the development of general purpose AI regulation”. In fact, to add Global South lenses to AI talks and ensure a more intersectional representation of interests, there is a role to play not only by governments but also civil society, the ultimate recipients of AI systems. The UN AI Advisory Body (2023:24) is currently open for consultations, “look[ing] forward to engaging with diverse stakeholders” and together shaping the vision for AI global governance. Furthermore, staying in the information loop and engaging in knowledge sharing on AI, e.g. at events such as the AI Safety Summits, can help Global South transition from passive policy recipient to a technological partner, one that also has the decision-making power to avert unfavourable regulations.</p> <h4 id="challenges-to-kingdons-approach">Challenges to Kingdon’s approach</h4> <p>In respect to Kingdon’s theory (2011), the essay risks being overconfident in arguing for an existence of a window of opportunity for Global South engagement offered by the “AI moment”. Yet, its call for more social policy research on AI global governance structures and regulations holds given its evident insufficiency, and the high significance of AI for development. It may be that through problem brokering and policy entrepreneurship, the Global South can either open or widen such a window, seizing it with the newly developed alternatives for AI global governance.</p> <p>However, there remains the challenging nature of global governance itself: a “lack of consensus” as its “inherent characteristic” (Pouliot and Thérien 2023:14) and a high level of uncertainty posed by fast developments in AI which complicates the decision-making processes. The Global North has strong interests in elite AI governance, prioritising, therefore, efficiency over equity. Furthemore, the Global South has already formed coalitions aimed at rebalancing power relations in multilateral institutions in the past, with little success. For example, Freeman (2018:78) depicts how since 1960s, the Group of Seventy Seven, a political bloc formed by Global South leaders in the UN, have “called for an ‘international enabling environment’ for development”, asking for more democratic and representative global governance arrangements, and for an equal voice in intergovernmental organisations. Yet, their limited success is mirrored in the lack of substantial changes to institutional arrangements of the UN or the decision-making power distribution.</p> <p>Finally, there is no singular Global South, but a multitude of marginally positioned entities in global power relations. Overestimating regional homogeneities risk “overgeneralising” (Sen 2001) populations and suppressing intersectionally vulnerable voices. Inclusive governance, therefore, is not necessarily about having “everyone at the table” but “having the right mix” (Chatham House 2021), which social policy research could contribute significantly to identifying. There is a conflict between the sheer diveristy in agendas and the need for relative unity to advance broader Global South interests in global governance of AI. Coalitions, therefore, might be effective for a limited period of time, as different trajectories of their members can make holding together less possible with time.</p> <h4 id="conclusion">Conclusion</h4> <p>Departing from the relationship between governing structures and development capabilities drawing on Sen’s (1999) work, and the risks posed by the emerging elitist AI regulations, this essay addressed the question of how Global South can strengthen their engagement in the global governance of AI. It built on Kingdon’s (2011) theory of policy windows to argue for the current convergence of problem definition, political will and available solutions, and consequently, for seizing that window to claim Global South seats at the AI roundtable. The proposed strategies included (1) building a coalition among Global South entities to advance common interests more effectively at the exisiting AI governance initiatives; (2) investing in AI talent, compute and data collection to equip the Global Majority with enablers for technological advancements; (3) participating in shaping the ongoing discussions on AI regulation both by Global South governmental and civil society actors to represent a broader spectrum of interests. This essay also aimed at addressing the existing gap in social policy research on governance of AI. Excluding the Global Majority from AI talks may lead to magnified levels of global inequalities by coupling economic and political disadvantages of Global South, and depriving individuals of capabilities for pursuing lives they value. Measuring AI governance success should be conditional on an active global participation. Still, there remain many more research puzzles to be tackled that social policy could heavily contribute to such as designing data governance or preventing global wealth concentration in the hands of a few AI companies.</p> <hr/> <h4 id="references">References</h4> <p>Adib-Moghaddam , A. (2023). Is Artificial Intelligence Racist? The Ethics of AI and the Future of Humanity. London: Bloomsbury Publishing.</p> <p>Biden, J. (2023). Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. [online] The White House. Available at: https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/ [Accessed 16 Jan. 2024].</p> <p>Chatham House (2021). Reflections on building more inclusive global governance. [online] Chatham House. Available at: https://www.chathamhouse.org/2021/04/reflections-building-more-inclusive-global-governance [Accessed 16 Jan. 2024].</p> <p>Crenshaw, K. (2019). On intersectionality: Essential writings. New York, NY: The New Press.</p> <p>Davis, J. (2012). Swiss Political Science Review Swiss Political Science Review Free Access A Critical View of Global Governance. Swiss Political Science Review, (18), pp.272–286.</p> <p>Freeman, D. (2018). The Global South at the UN: using international politics to re-vision the global. The Global South, (11), pp.71–91.</p> <p>Grindle, M. and Thomas, J. (1990) After the Decision: Implementing Policy Reforms in Developing Countries. World Development. Vol. 18 (8)</p> <p>Howlett, M., McConnel, A. and Perl, A. (2015). Streams and stages: Reconciling Kingdon and policy process theory. European Journal of Political Research, 54(3), pp.419–434.</p> <p>Jakobsson, E. (2021). How Climate-Induced Migration Entered the UN Policy Agenda in 2007–2010: A Multiple Streams Assessment. Politics and Governance, 9(4), pp.16–26.</p> <p>Kingdon (2011). Agendas, Alternatives, and Public Policies. 2nd ed. Boston: Longman. [1984]</p> <p>Knaggard, A. (2015). The Multiple Streams Framework and the problem broker. European Journal of Political Research, 54(3), pp.450–465.</p> <p>Marwala, T. (2019). Artificial intelligence, at Africa’s door. The UNESCO Courier, 2019(2), pp.56–57.</p> <p>Marwala, T., Fournier-Tombs, E. and Stinckwich, S. (2023). The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development. [online] United Nations University . Available at: https://unu.edu/publication/use-synthetic-data-train-ai-models-opportunities-and-risks-sustainable-development [Accessed 16 Jan. 2024].</p> <p>Moon, M. (2023). Searching for inclusive artificial intelligence for social good: Participatory governance and policy recommendations for making AI more inclusive and benign for society. Public Administration Review, 83(6), pp.1496–1505.</p> <p>Nicholls, E. (2018). Studying the state: a Global South perspective. Third World Thematics: A TWQ Journal, 3(4), pp.469–478.</p> <p>North, D. (1990). Institutions, Institutional Change and Economic Performance. Cambridge: Cambridge University Press.</p> <p>Obia, V. (2023). What can African countries do to regulate artificial intelligence? [online] London School of Economics and Political Science.</p> <p>Ocampo, J. (2016). Global Governance and Development. Oxford: Oxford University Press.</p> <p>OECD (2023), “A blueprint for building national compute capacity for artificial intelligence”, OECD Digital Economy Papers, No. 350, OECD Publishing, Paris.</p> <p>OECD.AI. (2023). Updates to the OECD’s definition of an AI system explained. [online] Available at: https://oecd.ai/en/wonk/ai-system-definition-update [Accessed 16 Jan. 2024].</p> <p>Pouliot, V. and Thérien, J-P. (2023). Introduction: The Politics of Global Governance. In: Global Policymaking: The Patchwork of Global Governance. Cambridge: Cambridge University Press, pp.1–21.</p> <p>Sampath, P. (2021). Governing Artificial Intelligence in an Age of Inequality. Global Policy, 12(S6), pp.21–31.</p> <p>Sen, A. (1999). Development as Freedom. New York: Alfred A. Knopf, Inc.</p> <p>Sen, A. (2001). A World Not Neatly Divided. [online] New York Times. Available at: https://www.nytimes.com/2001/11/23/opinion/a-world-not-neatly-divided.html [Accessed 16 Jan. 2024].</p> <p>Spivak, G. (1988). Can the Subaltern Speak? Die Philosophin, 14(27), pp.42–58.</p> <p>Toye, J. (2014). Assessing the G77: 50 years after UNCTAD and 40 years after the NIEO. Third World Quarterly, 35(10), pp.1759–1774.</p> <p>United Nations. (2023). Interim Report: Governing AI for Humanity. [online] Available at: https://www.un.org/en/ai-advisory-body [Accessed 16 Jan. 2024].</p> <p>Zürn, M. (2004). Global Governance and Legitimacy Problems. Government and Opposition, 39(2), pp.260–287.</p>]]></content><author><name></name></author><category term="international-development"/><category term="AI"/><summary type="html"><![CDATA[An introductory essay I wrote for my Social Policy in Development course at LSE. I draw on Sen's and Kingdon's theories to explore why exclusive AI governance may have detrimental effects on the global poor.]]></summary></entry></feed>