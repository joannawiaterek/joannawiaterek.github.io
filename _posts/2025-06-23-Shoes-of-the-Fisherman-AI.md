---
layout: post
title: "The Shoes of the Fisherman (1968) and Morality in AI Leadership"
date: 2025-06-23 6:40:16
description: Some brief weekend thoughts…
tags: [AI, Christianity]
---

*“(...) We are acutely conscious of Our duty to pay particular attention to the serious problem of world peace. (…) Our aim must be to educate mankind to sentiments and policies which are opposed to violent and deadly conflicts and to foster just, rational, and peaceful relations between States.”* [Pope Paul VI, 1964](https://www.vatican.va/content/paul-vi/en/encyclicals/documents/hf_p-vi_enc_06081964_ecclesiam.html)

I have recently watched the 1968 film  '[The Shoes of the Fisherman](https://en.wikipedia.org/wiki/The_Shoes_of_the_Fisherman_(film))', based on Morris West’s 1963 novel. It is a story of a Ukrainian Archbishop, Kiril Lakota, released from a Siberian labour camp after 20 years, sent to Rome, elevated to a Cardinal, and - unexpectedly - elected Pope. All that amid the context of the Cold War politics, widespread famine in China, and the looming threat of nuclear conflict. To me, Lakota embodies what I admire most in personal life and what I lack most in the AI industry: wisdom, discernment and humility. 

I couldn’t help but draw parallels to today’s threats to humanity posed by AI, the geopolitical tensions, and the rise of a new (American) Pope Leo XIV. There are three key things I wanted to double down on:

#### Wisdom | Moral Leadership in a Polarised World

Lakota refused to be weaponised by any of the political blocs. Instead, he pursued dialogue and his quiet authority of conscience.

Today, polarisation permeates multiple axes of the AI age. Geopolitically, the narrative of US-China AI competition [paralyses](https://www.techpolicy.press/the-politics-of-ai-benefit-sharing/) multilateral cooperation. Philosophically, AI safety advocates have become ostracised by the proponents of unrestrained innovation, leading to potentially disastrous policies, such as the [proposed](https://www.poynter.org/fact-checking/2025/ai-regulation-ban-one-big-beautiful-bill-trump-congress/) decade-long US ban on AI regulation. Economically, the already vast global inequality levels are at risk of radically [magnifying](https://www.imf.org/en/Publications/WP/Issues/2025/04/11/The-Global-Impact-of-AI-Mind-the-Gap-566129). 

But real leadership chooses long-term wisdom over short-term wins. And my hope is that as an AI governance community, we find the courage to navigate this polarisation, not with ambition or fear, but with moral grounding.

#### Discernment | Battle to Win vs People to Serve 

Spoiler alert: The film ends with Lakota pledging Church’s wealth to save the lives of the Chinese brothers and sisters in famine. That is a result of his deep private deliberation on how to lead the world into collaboration and peace.

His actions starkly contrast with hoarding AI resources (e.g. compute), power concentration, and unequal access to AI benefits. Like Lakota, we also need to reframe our challenges: from dominance to responsibility, from fear to care. I see AI governance as a vocation of care because these technologies, if stewarded wisely, could help people around the world live safer, fuller, and more meaningful lives. The responsibility of those steering AI development is to ensure exactly that. And so I ask myself, what the world would look like if the goal of AI development were not to “win”, but to serve.

#### Humility | AI Risks are Real

Every day, I walk through the city and wonder what our daily lives will feel like in 2, 5 or 10 years amid the vast AI [transformations](https://www.nber.org/reporter/2024number4/economics-transformative-ai). What [jobs](https://futurism.com/anthropic-ai-destroy-jobs) will we have, if any? How will we [value](https://intelligence-curse.ai/) ourselves, our role and contribution to society? Will we have the peace of mind to cherish our families? 

Lakota showed that leadership isn’t about certainty, but about conscience. He didn’t know immediately what to do about mitigating the global nuclear conflict, but he knew his core responsibilities and guiding principles. Today, policy-makers must accept the burden of leadership and navigate the potential AI threats amid differing priorities and complex technical [capabilities](https://www.gov.uk/government/publications/international-ai-safety-report-2025). The stakes are high: misjudging the severity of AI risks may cause all of humanity to suffer. And unfortunately, we are in no way prepared for the scale of disruption that many experts [warn](https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html) is coming. 

Humility doesn’t mean paralysis. It means remembering that we are custodians, not gods. That the point is not just to move fast, but to move wisely. Not to dominate, but to serve. 

Together, wisdom, discernment and humility may be our strongest weapons against an AI catastrophe. And I hope that Pope Leo XIV, who has stepped into the shoes of the fisherman, helps shape the morality of AI governance.

I’m currently also finishing a book, '[The Divine Plan](https://www.regnery.com/9781610171540/the-divine-plan/)', that depicts the relationship between President Ronald Reagan and Pope John Paul II, and their purpose-driven leadership to end the Cold War. Highly recommend!
