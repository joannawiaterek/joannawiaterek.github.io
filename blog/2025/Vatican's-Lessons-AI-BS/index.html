<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Vatican's Lessons for AI Benefit-Sharing | Joanna Wiaterek </title> <meta name="author" content="Joanna Wiaterek"> <meta name="description" content="A reflection on the potential contributions of the Vatican’s teachings in helping us inform prioritisation in AI benefit-sharing."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joannawiaterek.github.io/blog/2025/Vatican's-Lessons-AI-BS/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Joanna Wiaterek </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Vatican's Lessons for AI Benefit-Sharing</h1> <p class="post-meta"> June 04, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI,</a>   <a href="/blog/tag/christianity"> <i class="fa-solid fa-hashtag fa-sm"></i> Christianity</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Last update: 4/6/2025</p> <h2 id="introduction-ai-vs-humanitywho-serves-whom">Introduction: AI vs Humanity–Who serves whom?</h2> <p>Designing artificial intelligence (AI) so that it serves all of humanity–not just a few amongst us–is the defining challenge of this decade. Today’s innovation optimisation and AI race-dynamics, which result in the centralisation of AI resources and profits, compromises the universal human right to a share in scientific advancement and its benefits (Article 27; United Nations, <a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights" rel="external nofollow noopener" target="_blank">1948</a>).</p> <p>Amid these complex power-and-profit dynamics, the absence of a shared moral compass and prioritisation frameworks in international AI governance can lead to choices that further benefit the powerful and neglect urgent global needs. This reflection explores how Vatican-inspired moral principles may guide us through these policy challenges.</p> <p>Reflecting on the relationship between AI and peace, Pope Francis (<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html" rel="external nofollow noopener" target="_blank">2024</a>) emphasised that technology shall “serve our best human potential and our highest aspirations.” He revisited that narrative in Antiqua et Nova (<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html" rel="external nofollow noopener" target="_blank">2024</a>), where he wrote that “the order of things must be subordinate to the order of persons, and not the other way around.” I feel deeply empowered by the idea that AI tools could enhance what’s important and meaningful to me.</p> <p>However, I worry we are not exactly on track. The fast pace of improvements in AI capabilities behind closed doors, and the centralised decision-making among a few frontier labs on what AI is and what it should do, create a dynamic where it is AI that shapes our future, rather than the other way round. Paraphrasing Pope Francis’ words, it feels like humanity and the possibilities of our future are subordinate to the order of technological progress, instead of us designing and deploying AI towards the futures which truly fulfil our aspirations.</p> <p>In the face of the AI rush for efficiency, the goal of this post is to prompt a pause – a reflection. It won’t offer implementation guidelines or solutions, but it may lay a seed for future ones. I explore the potential contributions of the Vatican’s teachings in helping us inform prioritisation in AI benefit-sharing.</p> <h2 id="moral-vacancy-in-ai-benefit-sharing-priorities">Moral Vacancy in AI Benefit-Sharing Priorities</h2> <p>The international AI policy space lacks clear prioritisation of human-centred outcomes. While many AI ethics frameworks exist, many remain abstract or politically vulnerable to US-China tensions or frontier labs’ economic incentives. As a result, decisions are guided more by power and profit than by moral principle.</p> <p>International AI benefit-sharing refers to efforts that foster international access to AI’s economic or broader societal benefits (Dennis et al., <a href="https://www.governance.ai/research-paper/options-and-motivations-for-international-ai-benefit-sharing" rel="external nofollow noopener" target="_blank">2024</a>) and holds the potential to mitigate an array of challenges stemming from the current state of AI development. Through regulation and agreements, benefit-sharing could help us re-position AI in service to humanity, especially those historically left behind.</p> <p>International benefit-sharing won’t happen by default and requires a shared understanding of policy priorities. Currently, decisions around AI priorities are often shaped by competitive pressures, not moral commitments:</p> <ul> <li>Frontier labs race toward AGI, incentivised more by investor pressure than by public benefit.</li> <li>The US-China competition limits multilateral transparency and cooperation.</li> <li>Basic deployment opportunities—for example, AI in climate forecasting or low-resource healthcare—are overlooked in favour of speculative future gains.</li> </ul> <p>This leads to a troubling inversion: technology dictates our agenda, instead of serving a shared vision of human flourishing. Without clear priorities, we risk optimising for technological ambition rather than human need.</p> <p>On a personal level, amid claims regarding the whole of humanity – a noble, yet abstract notion behind which we can hide our selfish ambitions – I long to revisit my own heart and reflect on what values I bring into AI policy. It’s easy to speak of benefiting all people while neglecting the needs right in front of us—a friend, a colleague, a family member. If we can’t honour the dignity of individuals in our daily lives, how can we claim to act on behalf of the world?</p> <p>Pope Francis called for “a renewed wisdom of heart” (Antiqua et Nova, <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html" rel="external nofollow noopener" target="_blank">2024</a>). This stands in stark contrast to the technocratic language of AI development evoking efficiency and the deterministic nature of algorithms. As policy-makers, researchers or leaders, we face serious responsibilities regarding shaping AI to the benefit of all–those we know and those whom we’ll never know. Personally, I wish we preserved our values of mutual care and respect and the intrinsic value of human life as we design our futures.</p> <p>While there are existing ethical AI frameworks, such as the Final Report by the United Nation’s High-level Advisory Body on AI (<a href="https://www.un.org/sites/un2.un.org/files/governing_ai_for_humanity_final_report_en.pdf" rel="external nofollow noopener" target="_blank">2024</a>), UNESCO’s recommendations on AI ethics (<a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455" rel="external nofollow noopener" target="_blank">2021</a>), or even national AI strategies, among others, they either leave the guidelines in the realm of abstraction or are prone to political climates. This reflection on the Vatican’s contributions is an attempt to explore how its teachings could help us inform prioritisation in AI benefit-sharing. It is an invitation for the Vatican to engage more in setting the priorities for AI policies, and an invitation to all of us working on AI to pause and ask ourselves what we really care about.</p> <h2 id="the-vaticans-lessons-for-ai-benefit-sharing">The Vatican’s Lessons for AI Benefit-Sharing</h2> <p>Why the Vatican? Because its centuries-long expertise lies in humanity and community. Catholic Social Teaching, an area of Catholic doctrine focused on aspects such as human dignity, social justice, and wealth distribution, seems highly relevant for AI benefit-sharing. These teachings, whether you see them as theological or philosophical, can offer insights for navigating the design of AI systems that serve the global common good. There is also something about the Vatican’s view of the intrinsic value in human beings and our lives that is lacking from state- or private-actors’ agendas, whose incentives are subject to the fluctuating geopolitical winds.</p> <p>Moreover, the Vatican has already made significant attempts to engage with AI ethics. Alongside Pope Francis’ writings and the new Pope Leo XIV’s immediate reference, upon his election, to AI as a grand challenge of this century, the Rome Call for AI Ethics (<a href="https://www.romecall.org/wp-content/uploads/2022/03/RomeCall_Paper_web.pdf" rel="external nofollow noopener" target="_blank">2020</a>) brought together signatories from international organizations, governments, institutions and technology companies, and established <em>“a sense of shared responsibility […] in an effort to create a future in which digital innovation and technological progress grant man his centrality.”</em> The participants committed to AI development that <em>“serves every person and humanity as a whole; that respects the dignity of the human person, so that every individual can benefit from the advances of technology; and that does not have as its sole goal greater profit or the gradual replacement of people in the workplace.”</em></p> <p>I selected three headlines to discuss some aspects of the Catholic Social Teaching that could help us ground both intra- and inter-State AI benefit-sharing principles:</p> <h4 id="the-human-person-must-come-before-profit">The Human Person Must Come Before Profit</h4> <p>Catholic thought has long warned against economic systems that reduce people to instruments of production. In Rerum Novarum (<a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html" rel="external nofollow noopener" target="_blank">1891</a>), Pope Leo XIII condemned the exploitation of workers under industrial capitalism, asserting the primacy of the human person over the pursuit of profit. Applied to the context of AI, this principle challenges us to design systems that enhance human dignity. It urges us to ask: Are AI innovations serving the well-being of individuals, or merely driving economic efficiency? For example, technology transfers, as part of non-monetary benefit-sharing, should not be measured by GDP contribution alone, but by how these tools improve daily lives and life satisfaction. More concretely, this also suggests that future AI benefit-sharing agreements should include an obligation for companies profiting from global data flows to compensate the communities whose data they have extracted.</p> <p>In policy terms: profit-sharing mechanisms, ethical deployment standards, and labour protections for those displaced or augmented by AI are moral imperatives—not afterthoughts.</p> <h4 id="preferential-option-for-the-poor">Preferential Option for the Poor</h4> <p>A cornerstone of Catholic ethics, the “preferential option for the poor” asserts that social and political decisions should prioritise those most marginalised. This is not about charity, but long-term, structural justice—shaping systems so that those historically excluded are placed at the centre and gain agency over their destiny.</p> <p>In the AI context, this principle demands more than access: it requires deliberate prioritisation of the Global Majority, low-resource settings, and marginalised groups in AI research, development, and deployment. This might involve funding AI projects in indigenous languages, building local data infrastructures, or offering special concessions for compute access in developing countries.</p> <p>Global AI governance mechanisms can reflect this teaching by embedding equity at their core—as a starting point.</p> <h4 id="truth-in-service-of-the-common-good">Truth in Service of the Common Good</h4> <p>In a world increasingly shaped by algorithmic persuasion and performative policy, Catholic Social Teaching’s emphasis on truth is a necessary corrective. AI systems—especially generative ones—threaten to flood public discourse with falsehoods, deepen epistemic divides, and erode trust.</p> <p>This principle reminds us that benefit-sharing must be grounded not only in economic redistribution but also in the defence of shared truths. We need governance frameworks that uphold transparency, accuracy, and integrity in AI models, such as those used in information systems or education.</p> <p>Beyond fact-checking, this is a call for AI that serves what is deeply real and enduring: human relationships, intergenerational responsibility, and our shared moral aspirations. We must resist the temptation to optimise for short-term engagement or superficial metrics, and instead build AI that contributes to what Pope Francis called “<a href="https://catholicecology.net/blog/pope-francis-what-integral-human-development" rel="external nofollow noopener" target="_blank">integral human development</a>.”</p> <p>While rooted in religious tradition, these principles resonate far beyond church walls—echoing values found in existing treaties. Here are some examples (emphases mine):</p> <ul> <li>Declaration on Social Progress and Development (1969, UN General Assembly) <ul> <li>Article 13(a): <em>Equitable</em> sharing of scientific and technological advances by developed and developing countries, and a steady increase in the use of science and technology for the benefit of the social development of society.</li> </ul> </li> <li>Declaration on the Use of Scientific and Technological Progress (1975, UN General Assembly) <ul> <li>Aware that the <em>transfer of science and technology is one of the principal ways of accelerating the economic development of developing countries</em>,</li> <li>Article 3: All States shall take measures to ensure that scientific and technological achievements <em>satisfy the material and spiritual needs of all sectors of the population</em>.</li> </ul> </li> <li>Rio Declaration on Environment and Development (1992, UN Earth Summit) <ul> <li>Principle 6: The special situation and needs of <em>developing countries</em>, particularly the least developed and those most environmentally vulnerable, <em>shall be given special priority</em>.</li> </ul> </li> </ul> <p>Both the Vatican and existing human rights and development treaties provide solid foundations for setting priorities in benefit-sharing. Our challenge lies in transcending the complex geopolitical and economic tensions unique to AI and applying these guiding principles to this new layer of global governance.</p> <h2 id="moving-forward">Moving Forward</h2> <p>Moral reflections are prone to becoming romanticised debates lacking the world’s realism. It is implementation that is the hard part. But in moments of rapid change, such as AI development, we need ethical North Stars like the Vatican more than ever. Without them, policies risk being reactive and short-sighted.</p> <p>There is a large literature from previous international benefit-sharing agreements and the Holy See’s archives on the fundamental ethical non-negotiables that, as we build the international AI governance ecosystem, we should keep closely in mind despite the fast-paced and almost overpowering speed of technological innovation in comparison to our human pace. It is we who should subordinate and harness AI, not the other way round.</p> <p>As international AI governance takes further shape and the possibility emerges for a global convention on fair and equitable AI benefit-sharing, it is the existing moral teachings, such as those of the Vatican, that will help us construct this new layer of international law. Unfortunately, we may not have much time to do the thinking when the moment comes, so I encourage you to consider deeply today: What future do you want for our world?</p> <h2 id="further-readings">Further Readings</h2> <p><a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html" rel="external nofollow noopener" target="_blank">Rerum Novarum (May 15, 1891)</a> <a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20090629_caritas-in-veritate.html" rel="external nofollow noopener" target="_blank">Caritas in veritate (June 29, 2009)</a> <a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html" rel="external nofollow noopener" target="_blank">LVII World Day of Peace 2024 - Artificial Intelligence and Peace</a> <a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html" rel="external nofollow noopener" target="_blank">Dilexit nos (24 October 2024)</a> <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html" rel="external nofollow noopener" target="_blank">Antiqua et nova. Note on the Relationship Between Artificial Intelligence and Human Intelligence (28 January 2025)</a> <a href="https://www.vatican.va/roman_curia/pontifical_councils/justpeace/documents/rc_pc_justpeace_doc_20060526_compendio-dott-soc_en.html#INTRODUCTION" rel="external nofollow noopener" target="_blank">Compendium of the Social Doctrine of the Church</a></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/New-Global-Governance-Window/">New Global Governance Window: how the Global South can join the AI roundtable now.</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Vatican-US-China-AI-peace/">Could the Vatican mediate US-China AI peace?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Global-Governance-of-AI/">Global Governance of AI: preliminary questions</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Shoes-of-the-Fisherman-AI/">“'The Shoes of the Fisherman' (1968) and Morality in AI Leadership"</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Joanna Wiaterek. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>